{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "from IPython.display import Audio, display\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import librosa as lr\n",
    "import numpy as np\n",
    "import os\n",
    "from shutil import copy, rmtree\n",
    "from os.path import join as jp\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from scipy.io import wavfile as wf\n",
    "from time import time, sleep\n",
    "from input_data import prepare_words_list\n",
    "from glob import glob\n",
    "import hashlib\n",
    "from classes import get_classes, get_int2label, get_label2int\n",
    "from keras.layers import Input, Lambda\n",
    "from model import prepare_model_settings, relu6, overlapping_time_slice_stack\n",
    "from keras.applications.mobilenet import DepthwiseConv2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio\n",
    "from tensorflow.python.ops import io_ops\n",
    "from keras.layers import Input, Conv1D, Reshape\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "def my_load_model(fn):\n",
    "    return load_model(fn, {'relu6': relu6, 'DepthwiseConv2D': DepthwiseConv2D,\n",
    "                           'overlapping_time_slice_stack': overlapping_time_slice_stack})\n",
    "\n",
    "def pad_crop(data, desired_size=16000):\n",
    "    data_len = len(data)\n",
    "    if data_len < desired_size:\n",
    "        missing = desired_size - data_len\n",
    "        data = np.pad(data, (missing, 0), mode='constant')\n",
    "    else:\n",
    "        data = data[:desired_size]\n",
    "    return data\n",
    "\n",
    "def float_audio(x, sample_rate=16000, autoplay=False):\n",
    "    # avoid Audio normalizing the data\n",
    "    data = np.int16(x * 32768)\n",
    "    fn = '/tmp/%s.wav' % data[:5]\n",
    "    wf.write(fn, sample_rate, data)\n",
    "    display(Audio(filename=fn, rate=sample_rate, autoplay=autoplay))\n",
    "\n",
    "def plot_audio(data, sample_rate=16000, normed=False):\n",
    "    if not normed:\n",
    "        data = np.float32(data) / 32768\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(sample_rate), data)\n",
    "    plt.axis([0, sample_rate, -1, 1])\n",
    "    \n",
    "def center_pad(data, desired_size=16000):\n",
    "    missing = desired_size - len(data)\n",
    "    pad_left = missing // 2\n",
    "    pad_right = missing - pad_left\n",
    "    padded_data = np.pad(data, (pad_left, pad_right), mode='constant')\n",
    "    return padded_data\n",
    "\n",
    "def random_crop(data, desired_size=16000):\n",
    "    start = np.random.randint(len(data) - desired_size)\n",
    "    return data[start: start + desired_size]\n",
    "\n",
    "def normalized_read(fn, desired_size=16000):\n",
    "    rate, data = wf.read(fn)\n",
    "    data = np.float32(data) / 32768\n",
    "    assert rate == 16000\n",
    "    if len(data) < desired_size:\n",
    "        data = center_pad(data, desired_size=desired_size)\n",
    "    elif len(data) > desired_size:\n",
    "        data = random_crop(data, desired_size=desired_size)\n",
    "    return data\n",
    "\n",
    "def md5(fname):\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(fname, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sub1 = pd.read_csv('submission_033b.csv')  # 87% PLB\n",
    "sub2 = pd.read_csv('submission_017.csv')  # 87% PLB\n",
    "sub3 = pd.read_csv('submission_018.csv')  # 86% PLB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check where all three disagree\n",
    "unequal = ((sub1.label != sub2.label) & (sub1.label != sub3.label))\n",
    "print(\"%d of %d are unequal\" % (unequal.sum(), sub1.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display where classifiers disagree\n",
    "These samples are acutally quite hard!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = 'data/test/audio'\n",
    "disp_count = 0\n",
    "for i in range(len(unequal)):\n",
    "    if disp_count > 5:\n",
    "        break\n",
    "    if unequal[i] and np.random.rand() > 0.99:\n",
    "        fn = os.path.join(TEST_DIR, sub1.loc[i, 'fname'])\n",
    "        print(fn, ': ', sub1.loc[i, 'label'], \" vs \", sub2.loc[i, 'label'])\n",
    "        display(Audio(fn, autoplay=True))\n",
    "        sleep(1)\n",
    "        disp_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these \"hard\" ones\n",
    "for i in tqdm(range(len(unequal))):\n",
    "    if unequal[i]:\n",
    "        bn = sub1.loc[i, 'fname']\n",
    "        src_fn = os.path.join('data/test/audio', bn)\n",
    "        dst_fn = os.path.join('data/pseudo/audio/unknown', bn)\n",
    "        copy(src_fn, dst_fn)\n",
    "# when using as pseudo labels remove 'silence'! (e.g. ls *.wav | grep -v silence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show (predicted) test data distribution\n",
    "### Note that during training silence prob was 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_bar(submission):\n",
    "    counts = []\n",
    "    for label_name in submission.label.unique():\n",
    "        label_count = (submission.label == label_name).sum()\n",
    "        percent = (label_count / num_total) * 100.0\n",
    "        counts.append((label_name, percent))\n",
    "    print(counts)\n",
    "    plt.bar(range(len(counts)), [c[-1] for c in counts])\n",
    "    _ = plt.xticks(range(len(counts)), [c[0] for c in counts])\n",
    "    plt.grid('on')\n",
    "    plt.xlabel('Label names')\n",
    "    plt.ylabel('Precentage [%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_bar(sub1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compress and decompress using mu-law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav(fn):\n",
    "    rate, data = wf.read(fn)\n",
    "    assert rate == 16000\n",
    "    data = data / 32768\n",
    "    missing = 16000 - len(data)\n",
    "    data = np.pad(data, (missing, 0), mode='constant')\n",
    "    return data\n",
    "\n",
    "\n",
    "def compress(x, mu=255):\n",
    "    assert x.min() >= -1 and x.max() <= 1\n",
    "    compressed = np.sign(x) * np.log10(1.0 + mu * np.abs(x)) / np.log10(1.0 + mu)\n",
    "    return compressed\n",
    "\n",
    "def decompress(x, mu=255):\n",
    "    assert x.min() >= -1 and x.max() <= 1\n",
    "    decompressed= np.sign(x) * (1.0 / mu) * (np.power(1.0 + x, np.abs(x)) - 1.0)\n",
    "    return decompressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_sample = load_wav('data/test/audio/clip_001204892.wav')\n",
    "float_audio(up_sample)\n",
    "c = compress(up_sample)\n",
    "d = decompress(c)\n",
    "float_audio(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(data=np.int16(up_sample  * 32768), rate=16000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use average pooling to reduce signal size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import AveragePooling1D, Input, Reshape\n",
    "def avg_model(sample_rate=16000):\n",
    "    input_layer = Input([sample_rate])\n",
    "    x = input_layer\n",
    "    x = Reshape([-1, 1])(x)\n",
    "    x = AveragePooling1D(2)(x)\n",
    "    return Model(input_layer, x)\n",
    "\n",
    "model = avg_model()\n",
    "out = model.predict([up_sample.reshape((1, -1))]).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('Orginal')\n",
    "plt.plot(up_sample)\n",
    "plt.figure()\n",
    "plt.title('Subsamples')\n",
    "plt.plot(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_audio(out, sample_rate=len(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How is the padding handeled by decode_wav?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio\n",
    "from tensorflow.python.ops import io_ops\n",
    "\n",
    "wav_filename_placeholder = tf.placeholder(tf.string, [])\n",
    "wav_loader = io_ops.read_file(wav_filename_placeholder)\n",
    "wav_decoder = contrib_audio.decode_wav(\n",
    "    wav_loader, desired_channels=1)\n",
    "fns = sorted(glob('data/train/audio/go/*.wav'))\n",
    "short_fn = ''\n",
    "with tf.Session() as sess:\n",
    "    for fn in fns:\n",
    "        out = sess.run(wav_decoder.audio,\n",
    "                       {wav_filename_placeholder: fn_val})\n",
    "        if out.shape[0] != 16000:\n",
    "            short_fn = fn\n",
    "            print(fn)\n",
    "            break\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(short_fn, autoplay=True))\n",
    "sleep(1)\n",
    "float_audio(out, autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check how many samples are shorter than 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "train_fns = sorted(glob('data/train/audio/*/*.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav(fn):\n",
    "    rate, data = wf.read(fn)\n",
    "    assert rate == 16000\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "short_count = 0\n",
    "for fn in tqdm(train_fns):\n",
    "    data = load_wav(fn)\n",
    "    if len(data) != 16000:\n",
    "        short_count += 1\n",
    "print(\"Short: \", short_count)\n",
    "print(\"All: \", len(train_fns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize augmented training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import TensorBoard\n",
    "from callbacks import ConfusionMatrixCallback\n",
    "from model import speech_model, prepare_model_settings\n",
    "from input_data import AudioProcessor, prepare_words_list\n",
    "from classes import get_classes\n",
    "from IPython import embed  # noqa"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def data_gen(audio_processor, sess,\n",
    "             batch_size=128,\n",
    "             background_frequency=0.5, background_volume_range=0.2,\n",
    "             foreground_frequency=0.5, foreground_volume_range=0.2,\n",
    "             time_shift=(100.0 * 16000.0) / 1000,\n",
    "             mode='validation'):\n",
    "    offset = 0\n",
    "    if mode != 'training':\n",
    "        background_frequency = 0.0\n",
    "        background_volume_range = 0.0\n",
    "        foreground_frequency = 0.0\n",
    "        foreground_volume_range = 0.0\n",
    "        time_shift = 0\n",
    "    while True:\n",
    "        X, y = audio_processor.get_data(\n",
    "            how_many=batch_size, offset=0 if mode == 'training' else offset,\n",
    "            background_frequency=background_frequency,\n",
    "            background_volume_range=background_volume_range,\n",
    "            foreground_frequency=foreground_frequency,\n",
    "            foreground_volume_range=foreground_volume_range,\n",
    "            time_shift=time_shift, mode=mode, sess=sess)\n",
    "        offset += batch_size\n",
    "        if offset > ap.set_size(mode) - batch_size:\n",
    "              offset = 0\n",
    "        yield X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()\n",
    "data_dirs = ['data/train/audio']\n",
    "add_pseudo = True\n",
    "if add_pseudo:\n",
    "    data_dirs.append('data/pseudo/audio')\n",
    "compute_mfcc = False\n",
    "sample_rate = 16000\n",
    "batch_size = 100\n",
    "classes = get_classes(wanted_only=False)\n",
    "model_settings = prepare_model_settings(\n",
    "  label_count=len(prepare_words_list(classes)), sample_rate=sample_rate,\n",
    "  clip_duration_ms=1000, window_size_ms=30.0, window_stride_ms=10.0,\n",
    "  dct_coefficient_count=40)\n",
    "ap = AudioProcessor(\n",
    "  data_dirs=data_dirs,\n",
    "  silence_percentage=10.0,\n",
    "  unknown_percentage=7.0,\n",
    "  wanted_words=classes,\n",
    "  validation_percentage=10.0,\n",
    "  testing_percentage=0.0,\n",
    "  model_settings=model_settings,\n",
    "  compute_mfcc=compute_mfcc)\n",
    "train_gen = data_gen(ap, sess, batch_size=batch_size, mode='training')\n",
    "val_gen = data_gen(ap, sess, batch_size=batch_size, mode='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_count = 0\n",
    "while True:\n",
    "    if disp_count > 5:\n",
    "        break\n",
    "    X, y = next(train_gen)\n",
    "    for i in range(X.shape[0]):\n",
    "        if y[i].argmax() == 10:\n",
    "            sample = X[i, :].squeeze()\n",
    "            float_audio(sample, autoplay=True)\n",
    "            sleep(1)\n",
    "            disp_count += 1\n",
    "            # plt.figure()\n",
    "            # plt.axis([0, 16000, -1, 1])\n",
    "            # plt.plot(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create pseudo labels from consistent predictions\n",
    "### [v_001]: Sub1: 84% PLB, Sub2: 84% PLB, Sub3: 82%: 118078 consistend pseudo labels\n",
    "### [v_002]: Sub1: 87%, Sub2: 87%, Sub3: 88%: 140945 pseudo consistend pseudo labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = pd.read_csv('submission_098_leftloud_tta_all_labels.csv')  # 87% PLB\n",
    "sub2 = pd.read_csv('submission_096_leftloud_tta_all_labels.csv')  # 87% PLB\n",
    "sub3 = pd.read_csv('submission_091_leftloud_tta_all_labels.csv')  # 88% PLB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consistend = ((sub1.label == sub2.label) & (sub1.label == sub3.label))\n",
    "print(\"All: \", sub1.shape[0], \" consistend: \", consistend.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(sub1.shape[0])):\n",
    "    fn = sub1.loc[i, 'fname']\n",
    "    if fn != sub2.loc[i, 'fname'] or fn != sub3.loc[i, 'fname']:\n",
    "        print(\"Fatal error\")\n",
    "        break\n",
    "    if consistend[i]:\n",
    "        label = sub1.loc[i, 'label']\n",
    "        dst_fn = jp('data', 'pseudo', 'audio', label, fn)\n",
    "        src_fn = jp('data', 'test', 'audio', fn)\n",
    "        copy(src_fn, dst_fn, follow_symlinks=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new background noise from pseudo silence\n",
    "## Just concat 60 seconds of audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_silence_fns = sorted(glob('data/pseudo/silence/*.wav'))\n",
    "num_pseudo_noise = 5\n",
    "num_secs = 60\n",
    "for i in range(num_pseudo_noise):\n",
    "    background_fns = np.random.choice(\n",
    "        pseudo_silence_fns, num_secs, replace=False)\n",
    "    new_clip = []\n",
    "    for fn in background_fns:\n",
    "        rate, data = wf.read(fn)\n",
    "        new_clip.append(data)\n",
    "    new_clip = np.concatenate(new_clip).astype(np.int16)\n",
    "    out_fn = 'data/train/audio/_background_noise_/custom_pseudo_silence_%04d.wav' % i\n",
    "    # print(out_fn)\n",
    "    wf.write(out_fn, 16000, new_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?wf.write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listen to submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = get_classes(wanted_only=False, extend_reversed=True)\n",
    "[w for w in words if 'b' in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('submission_091_all_labels.csv')\n",
    "label2int = get_label2int(wanted_only=True)\n",
    "disp_count = 0\n",
    "for i in reversed(range(sub.shape[0])):\n",
    "    if disp_count >= 10:\n",
    "        break\n",
    "    fn = jp('data', 'test', 'audio', sub.loc[i, 'fname'])\n",
    "    label = sub.loc[i, 'label']\n",
    "    if label == 'go' and np.random.rand() > 0.8:\n",
    "        print(fn, label)\n",
    "        display(Audio(fn, autoplay=True))\n",
    "        sleep(1)\n",
    "        disp_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "sub = pd.read_csv('submission_034_all_labels.csv')\n",
    "label2int = get_label2int(wanted_only=True)\n",
    "disp_count = 0\n",
    "for i in reversed(range(sub.shape[0])):\n",
    "    if disp_count >= 2:\n",
    "        break\n",
    "    label = sub.loc[i, 'label']\n",
    "    if label == 'silence' and np.random.rand() > 0.999:\n",
    "        fn = jp('data', 'test', 'audio', sub.loc[i, 'fname'])\n",
    "        rate, data = wf.read(fn)\n",
    "        data = np.float32(data) / 32767\n",
    "        # data = np.sqrt(data) + 0.5\n",
    "        data = 10 ** (data) - 1.0\n",
    "        plot_audio(data, normed=True)\n",
    "        print(fn, label)\n",
    "        float_audio(data, autoplay=True)\n",
    "        sleep(1)\n",
    "        disp_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare two submissions\n",
    "# sub1 = pd.read_csv('submission_091_all_labels.csv')\n",
    "# sub2 = pd.read_csv('submission_091_4x_tta_all_labels.csv')\n",
    "\n",
    "sub1 = pd.read_csv('submission_091_all_labels.csv')\n",
    "sub2 = pd.read_csv('submission_091_leftloud_tta_all_labels.csv')\n",
    "num_different = 0\n",
    "\n",
    "for i in tqdm(reversed(range(sub1.shape[0]))):\n",
    "    fn = sub1.loc[i, 'fname']\n",
    "    assert fn == sub2.loc[i, 'fname']\n",
    "    label1 = sub1.loc[i, 'label']\n",
    "    label2 = sub2.loc[i, 'label']\n",
    "    if label1 != label2:\n",
    "        num_different += 1\n",
    "        print(\"%s vs. %s\" % (label1, label2))\n",
    "        in_fn = jp('data/test/audio', fn)\n",
    "        display(Audio(in_fn, autoplay=True))\n",
    "        sleep(1)\n",
    "print(\"%d of %d are different\" % (num_different, sub1.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listen to submission with probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Wanted: \", get_classes(wanted_only=True))\n",
    "print(\"All: \", get_classes(wanted_only=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('submission_100_leftloud_tta_all_labels_probs.csv')\n",
    "label2int = get_label2int(wanted_only=False)\n",
    "int2label = get_int2label(wanted_only=False)\n",
    "disp_count = 0\n",
    "for i in reversed(range(sub.shape[0])):\n",
    "    if disp_count >= 5:\n",
    "        break\n",
    "    fn = jp('data', 'test', 'audio', sub.loc[i, 'fname'])\n",
    "    label = sub.loc[i, 'label']\n",
    "    if label == 'no' and np.random.rand() > 0.99:\n",
    "        probs = sub.loc[i, label2int.keys()]\n",
    "        max_prob = probs.max()\n",
    "        if max_prob < 0.5:\n",
    "            plt.figure()\n",
    "            plt.title(str(disp_count))\n",
    "            plt.bar(range(len(probs)), probs)\n",
    "            plt.axis([0, len(probs), 0, 1])\n",
    "            plt.xticks(range(len(probs)), label2int.keys(), rotation='vertical')\n",
    "            display(Audio(fn, autoplay=True))\n",
    "            sleep(1)\n",
    "            disp_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct broken submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_broken = pd.read_csv('submission_012.csv')\n",
    "sub_all = pd.read_csv('submission_012_all_labels.csv')\n",
    "sub_broken.loc[(sub_all.label == 'unknown').values, 'label'] = 'silence'\n",
    "sub_broken.to_csv('submission_012_corrected.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('submission_012_corrected.csv')\n",
    "disp_count = 0\n",
    "for i in range(sub.shape[0]):\n",
    "    if disp_count >= 10:\n",
    "        break\n",
    "    fn = jp('data', 'test', 'audio', sub.loc[i, 'fname'])\n",
    "    label = sub.loc[i, 'label']\n",
    "    if label != 'unknown' and np.random.rand() > 0.9:\n",
    "        print(label)\n",
    "        display(Audio(fn, autoplay=True))\n",
    "        sleep(1)\n",
    "        disp_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('submission_012_all_labels.csv')\n",
    "counts = sub.label.value_counts()\n",
    "percent_counts = counts.apply(lambda x: np.round(100.0 * (x / sub.shape[0])))\n",
    "# print(counts)\n",
    "print(percent_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check what the generators are producing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.callbacks import TensorBoard\n",
    "from callbacks import ConfusionMatrixCallback\n",
    "from model import speech_model, prepare_model_settings\n",
    "from input_data import AudioProcessor, prepare_words_list\n",
    "from classes import get_classes\n",
    "from IPython import embed  # noqa\n",
    "\n",
    "\n",
    "def data_gen(audio_processor, sess,\n",
    "             batch_size=128,\n",
    "             background_frequency=0.5, background_volume_range=0.2,\n",
    "             foreground_frequency=0.5, foreground_volume_range=0.2,\n",
    "             time_shift_frequency=1.0, time_shift_range=[-2000, 0],\n",
    "             mode='validation', pseudo_frequency=0.4):\n",
    "  offset = 0\n",
    "  if mode != 'training':\n",
    "    background_frequency = 0.0\n",
    "    background_volume_range = 0.0\n",
    "    foreground_frequency = 0.0\n",
    "    foreground_volume_range = 0.0\n",
    "    pseudo_frequency = 0.0\n",
    "    time_shift_frequency = 0.0\n",
    "    time_shift_range = [0, 0]\n",
    "  while True:\n",
    "    X, y = audio_processor.get_data(\n",
    "        how_many=batch_size, offset=0 if mode == 'training' else offset,\n",
    "        background_frequency=background_frequency,\n",
    "        background_volume_range=background_volume_range,\n",
    "        foreground_frequency=foreground_frequency,\n",
    "        foreground_volume_range=foreground_volume_range,\n",
    "        time_shift_frequency=time_shift_frequency,\n",
    "        time_shift_range=time_shift_range,\n",
    "        mode=mode, sess=sess,\n",
    "        pseudo_frequency=pseudo_frequency)\n",
    "    offset += batch_size\n",
    "    if offset > ap.set_size(mode) - batch_size:\n",
    "      offset = 0\n",
    "    yield X, y\n",
    "\n",
    "\n",
    "# running_mean: -0.8 | running_std: 7.0\n",
    "# mfcc running_mean: -0.67 | running_std: 7.45\n",
    "# background_clamp running_mean: -0.00064 | running_std: 0.0774, p5: -0.074, p95: 0.0697  # noqa\n",
    "# 10 ** raw - 1.0 running_mean: 0.017 | 10 ** raw - 1.0 running_std: 0.28\n",
    "# np.log(11) ~ 2.4\n",
    "# np.log(12) ~ 2.5\n",
    "# np.log(32) ~ 3.5\n",
    "# np.log(48) ~ 3.9\n",
    "# 64727 training files\n",
    "if __name__ == '__main__':\n",
    "  # restrict gpu usage: https://stackoverflow.com/questions/34199233/how-to-prevent-tensorflow-from-allocating-the-totality-of-a-gpu-memory  # noqa\n",
    "  gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.90)\n",
    "  sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "  K.set_session(sess)\n",
    "  data_dirs = ['data/train/audio']\n",
    "  add_pseudo = True\n",
    "  if add_pseudo:\n",
    "    data_dirs.append('data/pseudo/audio')\n",
    "  output_representation = 'raw'\n",
    "  sample_rate = 16000\n",
    "  batch_size = 384\n",
    "  classes = get_classes(wanted_only=False, extend_reversed=False)\n",
    "  model_settings = prepare_model_settings(\n",
    "      label_count=len(prepare_words_list(classes)), sample_rate=sample_rate,\n",
    "      clip_duration_ms=1000, window_size_ms=30.0, window_stride_ms=10.0,\n",
    "      dct_coefficient_count=40)\n",
    "  ap = AudioProcessor(\n",
    "      data_dirs=data_dirs, wanted_words=classes,\n",
    "      silence_percentage=15.0, unknown_percentage=5.0,\n",
    "      validation_percentage=10.0, testing_percentage=0.0,\n",
    "      model_settings=model_settings,\n",
    "      output_representation=output_representation)\n",
    "  train_gen = data_gen(ap, sess, batch_size=batch_size, mode='training')\n",
    "  val_gen = data_gen(ap, sess, batch_size=batch_size, mode='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(int2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2label = get_int2label(wanted_only=False)\n",
    "X, y = next(train_gen)\n",
    "for j in range(X.shape[0]):\n",
    "    label = int2label[y[j].argmax()]\n",
    "    if label == 'sheila':\n",
    "        data = X[j, :].squeeze()\n",
    "        float_audio(data, autoplay=True)\n",
    "        sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ap.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted_words = get_classes(wanted_only=True)\n",
    "print(wanted_words)\n",
    "labels2int = {v: k for k, v in ap.word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf data/train/audio/_silence_\n",
    "!mkdir data/train/audio/_silence_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save silence samples to '_silence_'\n",
    "disp_count = 0\n",
    "for i in range(100):\n",
    "    print(disp_count)\n",
    "    if disp_count > 100:\n",
    "        break\n",
    "    X, y = next(train_gen)\n",
    "    y = y.argmax(axis=-1)\n",
    "    for j in range(len(y)):\n",
    "        if y[j] == 0:\n",
    "            print(labels2int[y[j]])\n",
    "            out_fn = jp('data/train/audio/_silence_/%05d.wav' % disp_count)\n",
    "            data = np.int16(X[j, :] * 32768)\n",
    "            wf.write(out_fn, 16000, data)\n",
    "            # float_audio(X[j, :], autoplay=True)\n",
    "            # sleep(1)\n",
    "            disp_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and check where we go wrong in the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = speech_model(\n",
    "  'conv_1d_time',\n",
    "  model_settings['fingerprint_size'] if compute_mfcc else sample_rate,\n",
    "  num_classes=model_settings['label_count'])\n",
    "model.load_weights('checkpoints_014/ep-039-loss-0.173.hdf5')\n",
    "disp_count = 0\n",
    "for i in range(ap.set_size('validation') // batch_size):\n",
    "    if disp_count >= 10:\n",
    "        break\n",
    "    X, y_true = next(val_gen)\n",
    "    y_true = y_true.argmax(axis=-1)\n",
    "    y_pred = model.predict(X).argmax(axis=-1)\n",
    "    for j in range(len(y_true)):\n",
    "        if y_true[j] != y_pred[j] and np.random.rand() > 0.5:\n",
    "            l_true = labels2int[y_true[j]]\n",
    "            l_pred = labels2int[y_pred[j]]\n",
    "            print(\"Pred: %s, Actual: %s\" % (l_pred, l_true))\n",
    "            float_audio(X[j, :], autoplay=True)\n",
    "            sleep(1)\n",
    "            disp_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create \"unknown\" words\n",
    "### Just reverse some of the unwanted words. Reversing the wanted words might actually cause some problems when using global pooling in the end?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exclude_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted_words = get_classes(wanted_only=True)\n",
    "# wow reversed is wow! one reversed sounds like no!\n",
    "# dog vs go :P\n",
    "exclude_words = wanted_words + ['_background_noise_', 'wow', 'one', 'dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = sorted(glob(jp('data', 'train', 'audio', '*', '*.wav')))\n",
    "print(len(fns))\n",
    "fns = [fn for fn in fns if fn.split('/')[-2] not in exclude_words]\n",
    "print(len(fns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_classes = list(set([fn.split('/')[-2] for fn in fns]))\n",
    "# new_classes.remove('_silence_')\n",
    "new_classes = ['new_' + new_class[::-1] for new_class in new_classes]\n",
    "print(new_classes)\n",
    "for new_class in new_classes:\n",
    "    new_dir = jp('data/train/audio', new_class)\n",
    "    if os.path.exists(new_dir):\n",
    "        rmtree(new_dir)\n",
    "    os.mkdir(new_dir)\n",
    "    print(\"created %s\" % new_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(fns)\n",
    "# fn_selection = np.random.choice(fns, size=5000, replace=False)\n",
    "fn_selection = fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there (often) 5 times the same speaker said the same word\n",
    "# \n",
    "# ./eight/5fadb538_nohash_4.wav\n",
    "# ./eight/5fadb538_nohash_3.wav\n",
    "# ./eight/5fadb538_nohash_2.wav\n",
    "# ./eight/5fadb538_nohash_1.wav\n",
    "# ./eight/5fadb538_nohash_0.wav\n",
    "\n",
    "counter = {cn: 0 for cn in new_classes}\n",
    "for fn in tqdm(fn_selection):\n",
    "    cn = 'new_' + fn.split('/')[-2][::-1]\n",
    "    sample_rate, data = wf.read(fn)\n",
    "    bn = os.path.basename(fn)\n",
    "    dst = jp('data', 'train', 'audio', cn,\n",
    "             \"%06d.wav\" % counter[cn])\n",
    "    counter[cn] += 1\n",
    "    data = data[::-1]\n",
    "    wf.write(dst, sample_rate, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take a look at the noise files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_files = sorted(glob(jp('data', 'train', 'audio', '_background_noise_', '*.wav')))\n",
    "background_volumne = 0.8\n",
    "for fn in background_files[5:6]:\n",
    "    print(fn)\n",
    "    rate, data = wf.read(fn)\n",
    "    if len(data) > 16000:\n",
    "        data = data[:16000]\n",
    "    data = np.float32(data) / 32768\n",
    "    data *= background_volumne\n",
    "    print(data.max())\n",
    "    wf.write('tmp.wav', 16000, np.int16(data * 32767))\n",
    "    plot_audio(data, normed=True)\n",
    "    display(Audio('tmp.wav', autoplay=True))\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?wf.write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take a look at \"happy\" files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_files = sorted(glob(jp('data', 'train', 'audio', 'happy', '*.wav')))\n",
    "volumne = 10**1\n",
    "for fn in background_files[5:6]:\n",
    "    print(fn)\n",
    "    rate, data = wf.read(fn)\n",
    "    if len(data) > 16000:\n",
    "        data = data[:16000]\n",
    "    data = np.float32(data) / 32768\n",
    "    data *= volumne\n",
    "    data = np.clip(data, -1, 1)\n",
    "    print(data.max())\n",
    "    wf.write('tmp.wav', 16000, np.int16(data * 32767))\n",
    "    plot_audio(data, normed=True)\n",
    "    display(Audio('tmp.wav', autoplay=True))\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Majority vote submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import join as jp\n",
    "from shutil import copy\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "sub_fns = ['submission_011.csv', 'submission_017.csv',\n",
    "           'submission_018.csv', 'submission_014.csv',\n",
    "           'submission_020.csv']\n",
    "subs = [pd.read_csv(sub_fn) for sub_fn in sub_fns]\n",
    "\n",
    "fname, label = [], []\n",
    "clear_majority = 0\n",
    "for i in tqdm(range(subs[0].shape[0])):\n",
    "    fname.append(subs[0].loc[i, 'fname'])\n",
    "    label_counts = {}\n",
    "    for sub in subs:\n",
    "        ll = sub.loc[i, 'label']\n",
    "    if ll in label_counts:\n",
    "        label_counts[ll] += 1\n",
    "    else:\n",
    "        label_counts[ll] = 1\n",
    "\n",
    "    maj_label = max(label_counts, key=label_counts.get)\n",
    "    if label_counts[maj_label] > 2:\n",
    "        clear_majority += 1\n",
    "    else:\n",
    "        # in trouble save the wav files!\n",
    "        src = jp('data', 'test', 'audio', fname[-1])\n",
    "        dst = jp('split_decision', str(label_counts) + fname[-1])\n",
    "        copy(src, dst)\n",
    "    # resolve tie by chosing 'unknown' or 'silence' if available\n",
    "    if 'unknown' in label_counts and 'silence' in label_counts:\n",
    "        maj_label = 'silence'\n",
    "    elif 'unknown' in label_counts:\n",
    "        maj_label = 'unknown'\n",
    "    elif 'silence' in label_counts:\n",
    "        maj_label = 'silence'\n",
    "    label.append(maj_label)\n",
    "\n",
    "pd.DataFrame({'fname': fname, 'label': label}).to_csv(\n",
    "    'majority_sub_011.csv', index=False)\n",
    "print(\"Done! Got a clear majority for %d of %d samples.\"\n",
    "      % (clear_majority, subs[0].shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate more background noise\n",
    "## The idea is to take the reversed words and average some of them up to generate ~30s tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unwanted words reversed\n",
    "fns = sorted(glob(jp('data', 'train', 'audio', 'unwrev', '*.wav')))\n",
    "print(len(fns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "louder = 16.0  # make it louder!\n",
    "sample_secs = 30\n",
    "total_new = 0\n",
    "num_noise_tracks = 400\n",
    "noise_track = []\n",
    "noise_track_counter = 0\n",
    "sample_track = []\n",
    "sample_counter = 0\n",
    "for fn in tqdm(fns):\n",
    "    sample_rate, data = wf.read(fn)\n",
    "    data = np.float32(data) / 32768\n",
    "    assert sample_rate == 16000\n",
    "    data = center_pad(data)\n",
    "    shift = np.random.randint(16000)\n",
    "    data = np.roll(data, shift)\n",
    "    sample_track.append(data)\n",
    "    sample_counter += 1\n",
    "    if sample_counter == sample_secs:\n",
    "        noise_track.append(np.concatenate(sample_track))\n",
    "        sample_track = []\n",
    "        sample_counter = 0\n",
    "        noise_track_counter += 1\n",
    "        if noise_track_counter == num_noise_tracks:\n",
    "            noise_track = np.array(noise_track)\n",
    "            noise_track = np.mean(noise_track, axis=0) * louder\n",
    "            noise_track = np.int16(noise_track * 32768)\n",
    "            out_fn = jp('data', 'train', 'audio', '_background_noise_', 'silence_please_%04d.wav' % total_new)\n",
    "            wf.write(out_fn, 16000, noise_track)\n",
    "            print(out_fn)\n",
    "            display(Audio(out_fn))\n",
    "            noise_track = []\n",
    "            noise_track_counter = 0\n",
    "            total_new += 1\n",
    "            if total_new == 2:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does foreground with mixed background sound?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_noise_fns = sorted(glob('data/train/audio/_background_noise_/*.wav'))\n",
    "idx = -3\n",
    "print(background_noise_fns[idx])\n",
    "display(Audio(background_noise_fns[idx], autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foreground_fns = sorted(glob('data/train/audio/go/*.wav'))\n",
    "for i in range(3):\n",
    "    foreground_fn = np.random.choice(foreground_fns)\n",
    "    foreground = normalized_read(foreground_fn)\n",
    "    background_fn = np.random.choice(background_noise_fns)\n",
    "    # background_fn = background_noise_fns[-3]\n",
    "    print(background_fn)\n",
    "    background = normalized_read(background_fn)\n",
    "    mixed = np.random.uniform(0.8, 1.2) * foreground + 0.3 * background  # np.random.uniform(0, 2)\n",
    "    mixed = np.clip(mixed, -1, 1)\n",
    "    float_audio(mixed, autoplay=True)\n",
    "    plot_audio(mixed, normed=True)\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do the models perform on the validation set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import TensorBoard\n",
    "from model import speech_model, prepare_model_settings\n",
    "from input_data import AudioProcessor, prepare_words_list\n",
    "from keras.models import load_model\n",
    "from classes import get_classes\n",
    "\n",
    "\n",
    "def data_gen(audio_processor, sess,\n",
    "             batch_size=128,\n",
    "             background_frequency=0.5, background_volume_range=0.2,\n",
    "             foreground_frequency=1.0, foreground_volume_range=3.0,\n",
    "             time_shift=(100.0 * 16000.0) / 1000,\n",
    "             mode='validation'):\n",
    "    offset = 0\n",
    "    if mode != 'training':\n",
    "        background_frequency = 0.0\n",
    "        background_volume_range = 0.0\n",
    "        foreground_frequency = 0.0\n",
    "        foreground_volume_range = 0.0\n",
    "        time_shift = 0\n",
    "\n",
    "    while True:\n",
    "        X, y = audio_processor.get_data(\n",
    "            how_many=batch_size, offset=0 if mode == 'training' else offset,\n",
    "            background_frequency=background_frequency,\n",
    "            background_volume_range=background_volume_range,\n",
    "            foreground_frequency=foreground_frequency,\n",
    "            foreground_volume_range=foreground_volume_range,\n",
    "            time_shift=time_shift, mode=mode, sess=sess)\n",
    "        offset += batch_size\n",
    "        if offset > ap.set_size(mode) - batch_size:\n",
    "            offset = 0\n",
    "        yield X, y\n",
    "\n",
    "\n",
    "sess = K.get_session()\n",
    "data_dirs = ['data/train/audio']\n",
    "add_pseudo = False\n",
    "if add_pseudo:\n",
    "    data_dirs.append('data/pseudo/audio')\n",
    "compute_mfcc = False\n",
    "sample_rate = 16000\n",
    "batch_size = 64\n",
    "classes = get_classes(wanted_only=False)\n",
    "model_settings = prepare_model_settings(\n",
    "  label_count=len(prepare_words_list(classes)), sample_rate=sample_rate,\n",
    "  clip_duration_ms=1000, window_size_ms=30.0, window_stride_ms=10.0,\n",
    "  dct_coefficient_count=40)\n",
    "ap = AudioProcessor(\n",
    "  data_dirs=data_dirs,\n",
    "  silence_percentage=15.0,\n",
    "  unknown_percentage=7.0,\n",
    "  wanted_words=classes,\n",
    "  validation_percentage=10.0,\n",
    "  testing_percentage=0.0,\n",
    "  model_settings=model_settings,\n",
    "  compute_mfcc=compute_mfcc)\n",
    "train_gen = data_gen(ap, sess, batch_size=batch_size, mode='training')\n",
    "val_gen = data_gen(ap, sess, batch_size=batch_size, mode='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fns = [\n",
    "    'checkpoints_019/ep-022-vl-0.2916.hdf5',\n",
    "    'checkpoints_018/ep-049-vl-0.2185.hdf5',\n",
    "    'checkpoints_017/ep-036-vl-0.1969.hdf5'\n",
    "]\n",
    "\n",
    "models = []\n",
    "for model_fn in model_fns:\n",
    "    model = load_model(model_fn)\n",
    "    models.append((model_fn, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on validation set\n",
    "for model in models:\n",
    "    out = model.evaluate_generator(\n",
    "        val_gen, steps=ap.set_size('validation') // batch_size)\n",
    "    print(model_fn, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict samples with models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ap.words_list), len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(val_gen)\n",
    "sample_idx = 10\n",
    "float_audio(X[sample_idx, :], autoplay=True)\n",
    "out_probs = []\n",
    "for model_fn, model in models:\n",
    "    y_preds = model.predict(X)\n",
    "    out_probs.append((model_fn, y_preds[sample_idx]))\n",
    "\n",
    "for fn, pred in out_probs:\n",
    "    plt.figure()\n",
    "    plt.title(fn)\n",
    "    plt.bar(range(len(pred)), pred)\n",
    "    plt.xticks(range(len(pred)), ap.words_list, rotation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrong ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_plots = 2\n",
    "plot_c = 0\n",
    "model = models[-1][-1]\n",
    "while plot_c < max_plots:\n",
    "    X, y = next(val_gen)\n",
    "    y_preds = model.predict(X)\n",
    "    for i, y_pred in enumerate(y_preds):\n",
    "        if plot_c >= max_plots:\n",
    "            break\n",
    "        if y_pred.argmax() != y[i].argmax():\n",
    "            float_audio(X[i, :], autoplay=True)\n",
    "            sleep(1)\n",
    "            plt.figure()\n",
    "            plt.title(\"Pred: %s, Actual: %s\"\n",
    "                      % (ap.words_list[y_pred.argmax()], ap.words_list[y[i].argmax()]))\n",
    "            plt.bar(range(len(y_pred)), y_pred)\n",
    "            plt.xticks(range(len(y_pred)), ap.words_list, rotation='vertical')\n",
    "            plot_c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What happens if we just feed plain silence e.g. all 0?\n",
    "### Looks good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((2, 16000), dtype=np.float32)\n",
    "pred = model.predict(X)\n",
    "float_audio(X[0, :], autoplay=True)\n",
    "sleep(1)\n",
    "plt.figure()\n",
    "plt.title(\"Silence pred\")\n",
    "plt.bar(range(len(pred[0])), pred[0])\n",
    "_ = plt.xticks(range(len(pred[0])), ap.words_list, rotation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How about the noise files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_fns[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_fns = glob(jp('data/train/audio/_background_noise_/*.wav'))\n",
    "X = []\n",
    "for noise_fn in noise_fns:\n",
    "    X.append(normalized_read(noise_fn))\n",
    "X = np.float32(X)\n",
    "# change volumne\n",
    "X *= 0.2\n",
    "y_pred = model.predict(X)\n",
    "for i in range(X.shape[0]):\n",
    "    # float_audio(X[0, :], autoplay=True)\n",
    "    # sleep(1)\n",
    "    plt.figure()\n",
    "    plt.title(\"Noise pred: %s\" % noise_fns[i])\n",
    "    plt.bar(range(len(y_pred[i])), y_pred[i])\n",
    "    _ = plt.xticks(range(len(y_pred[i])), ap.words_list, rotation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission with averaged probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_fns = [\n",
    "    'submission_102_tta_leftloud.csv',\n",
    "    'submission_091_leftloud_tta.csv',\n",
    "    'submission_098_leftloud_tta.csv']\n",
    "sub_fns = [fn.replace('.csv', '_all_labels_probs.csv')\n",
    "           for fn in sub_fns]\n",
    "\n",
    "subs = []\n",
    "for sub_fn in sub_fns:\n",
    "    subs.append(pd.read_csv(sub_fn))\n",
    "\n",
    "wanted_words = prepare_words_list(get_classes(wanted_only=True))\n",
    "int2label = get_int2label(wanted_only=False)\n",
    "label2int = get_label2int(wanted_only=False)\n",
    "\n",
    "avg = 0.0\n",
    "for sub in subs:\n",
    "    avg += sub.loc[:, label2int.keys()].values / len(subs)\n",
    "\n",
    "print(avg.sum(axis=1)[10:20])\n",
    "probabilities = avg\n",
    "print(probabilities.shape)\n",
    "preds = probabilities.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_label = []\n",
    "ensemble_sub = subs[0].copy()\n",
    "for i in tqdm(range(ensemble_sub.shape[0])):\n",
    "    label = int2label[preds[i]]\n",
    "    # print(\"%s with: %.3f\" % (label, probabilities[i, preds[i]]))\n",
    "    label = label if label != '_silence_' else 'silence'\n",
    "    label = label if label != '_unknown_' else 'unknown'\n",
    "    # label = label if label == 'silence' or label in wanted_words else 'unknown'\n",
    "    ensemble_label.append(label)\n",
    "\n",
    "ensemble_sub['label'] = ensemble_label\n",
    "ensemble_sub[['fname', 'label']].to_csv('prob_ensemble_024_all_labels.csv', index=False)\n",
    "ensemble_sub.loc[:, label2int.keys()] = probabilities\n",
    "ensemble_sub.to_csv('prob_ensemble_024_all_labels_probs.csv', index=False)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_label = []\n",
    "ensemble_sub = subs[0].copy()\n",
    "small_prob_counter = 0\n",
    "prob_thresh = 0.2\n",
    "for i in tqdm(range(ensemble_sub.shape[0])):\n",
    "    label = int2label[preds[i]]\n",
    "    label = label if label != '_silence_' else 'silence'\n",
    "    label = label if label != '_unknown_' else 'unknown'\n",
    "    label = label if label == 'silence' or label in wanted_words else 'unknown'\n",
    "    # handle \"small\" probs\n",
    "    max_prob = probabilities[i, preds[i]]\n",
    "    if max_prob < prob_thresh:\n",
    "        small_prob_counter += 1\n",
    "        src_fn = jp('data/test/audio', ensemble_sub.loc[i, 'fname'])\n",
    "        dst_fn = jp('split_decision', '%s_%.3f.wav'\n",
    "                    % (label, max_prob))\n",
    "        copy(src_fn, dst_fn)\n",
    "        # map small prob words (not silence) to unknown\n",
    "        label = label if label == 'silence' else 'unknown'\n",
    "    ensemble_label.append(label)\n",
    "\n",
    "\n",
    "print(\"%d of %d with small prob\" % (small_prob_counter, ensemble_sub.shape[0]))\n",
    "ensemble_sub['label'] = ensemble_label\n",
    "ensemble_sub[['fname', 'label']].to_csv(\n",
    "    'prob_ensemble_024_thresh_%.2f_map_to_unknown.csv' % prob_thresh, index=False)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find duplicates\n",
    "## https://www.kaggle.com/c/tensorflow-speech-recognition-challenge/discussion/44687"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fns = sorted(glob('data/train/audio/*/*.wav'))\n",
    "test_fns = sorted(glob('data/test/audio/*.wav'))\n",
    "all_fns = train_fns + test_fns\n",
    "print(\"%d train, %d test, %d total\"\n",
    "      % (len(train_fns), len(test_fns), len(all_fns)))\n",
    "all_fns = all_fns[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('md5sums.p'):\n",
    "    md5sums = {}\n",
    "    for fn in tqdm(all_fns):\n",
    "        if fn in md5sums:\n",
    "            print(\"Double fn!\", fn)\n",
    "        checksum = md5(fn)\n",
    "        md5sums[fn] = checksum\n",
    "    # cache\n",
    "    data = {'md5sums': md5sums}\n",
    "    with open('md5sums.p', 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "with open('md5sums.p', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    md5sums = data['md5sums']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {}\n",
    "checksum_fn = {v: k for k, v in md5sums.items()}\n",
    "for fn, checksum in md5sums.items():\n",
    "    if checksum in counts:\n",
    "        counts[checksum] += 1\n",
    "    else:\n",
    "        counts[checksum] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_counts = []\n",
    "check_to_fns = {}\n",
    "for checksum, count in counts.items():\n",
    "    fn = checksum_fn[checksum]\n",
    "    fn_counts.append((fn, count))\n",
    "    if checksum in check_to_fns:\n",
    "        if fn not in check_to_fns[fn]:\n",
    "            check_to_fns[fn].append(fn)\n",
    "        else:\n",
    "            check_to_fns[fn] = [fn]\n",
    "fn_counts = sorted(fn_counts, key=lambda x: x[-1], reverse=True)\n",
    "print(fn_counts[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [(k, v) for k, v in counts.items() if v == 3710][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mist_fns = [fn for fn, s in md5sums.items() if s == a[0]]\n",
    "bns = [os.path.basename(fn) for fn in mist_fns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all silence -.- check that we got it right anyway ...\n",
    "some_sub = pd.read_csv('submission_017.csv')\n",
    "for i in range(some_sub.shape[0]):\n",
    "    fn = some_sub.loc[i, 'fname']\n",
    "    if fn in bns:\n",
    "        label = some_sub.loc[i, 'label']\n",
    "        if label != 'silence':\n",
    "            print(label)\n",
    "# check! That was useless -.-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listen test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fns = sorted(glob('data/test/audio/*.wav'))\n",
    "print(len(test_fns))\n",
    "disp_count = 0\n",
    "for test_fn in test_fns:\n",
    "    if disp_count > 10:\n",
    "        break\n",
    "    if np.random.rand() > 0.7:\n",
    "        print(test_fn)\n",
    "        display(Audio(filename=test_fn,\n",
    "                      rate=16000,\n",
    "                      autoplay=True))\n",
    "        sleep(1)\n",
    "        disp_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore subsampled representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fns = sorted(glob('data/test/audio/*.wav'))\n",
    "some_fn = np.random.choice(test_fns)\n",
    "rate, data = wf.read(some_fn)\n",
    "data = np.float32(data) / 32768\n",
    "assert rate == 16000\n",
    "plt.figure()\n",
    "plt.plot(range(len(data)), data, 'g')\n",
    "display(Audio(some_fn, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "step = 10\n",
    "colors = ['r', 'g', 'b', 'y', 'b']\n",
    "for i in range(3):\n",
    "    data_slice = data[0::step]\n",
    "    data_slice = np.roll(data_slice, int(-i * 400))\n",
    "    plt.plot(range(len(data_slice)), data_slice, colors[i])\n",
    "    float_audio(data_slice, sample_rate=int(16000 / step), autoplay=True)\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(some_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "colors = ['r', 'g', 'b', 'y']\n",
    "step = 3\n",
    "for i in range(step):\n",
    "    sub = data[i::step]\n",
    "    plt.plot(range(len(sub)), sub + 2 * i, colors[i % len(colors)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 20\n",
    "float_audio(data[::step], sample_rate=int(16000 / step), autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same thing in keras/tf\n",
    "def time_slice_stack(x, step):\n",
    "    x_slices = []\n",
    "    for i in range(step):\n",
    "        x_slice = x[:, i::step]\n",
    "        x_slice = K.expand_dims(x_slice, axis=-1)\n",
    "        x_slices.append(x_slice)\n",
    "    x_slices = K.concatenate(x_slices, axis=-1)\n",
    "    print(x_slices.shape)\n",
    "    return x_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=[16000])\n",
    "x = input_layer\n",
    "x = Lambda(lambda x: time_slice_stack(x, 2))(x)\n",
    "model = Model(input_layer, x)\n",
    "out = model.predict(data.reshape((1, 16000))).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check input representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_show_samples(label='stop'):\n",
    "    fns = sorted(glob('data/train/audio/%s/*.wav' % label))\n",
    "    disp_count = 0\n",
    "    for fn in fns:\n",
    "        if disp_count > 3:\n",
    "            break\n",
    "        rate, data = wf.read(fn)\n",
    "        data = np.float32(data) / 32768\n",
    "        data = pad_crop(data)\n",
    "        print(fn)\n",
    "        plt.figure()\n",
    "        plt.imshow(data.reshape((400, 40)).T)\n",
    "        plt.show()\n",
    "        display(float_audio(data, autoplay=True))\n",
    "        sleep(1)\n",
    "        disp_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_show_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now check mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_samples = 16000\n",
    "window_size_samples = 480\n",
    "window_stride_samples = 160\n",
    "dct_coefficient_count = 40\n",
    "magnitude_squared = False\n",
    "wav_filename_placeholder = tf.placeholder(tf.string, [])\n",
    "wav_loader = io_ops.read_file(wav_filename_placeholder)\n",
    "wav_decoder = contrib_audio.decode_wav(\n",
    "  wav_loader, desired_channels=1,\n",
    "  desired_samples=desired_samples)\n",
    "clamped = tf.clip_by_value(wav_decoder.audio, -1.0, 1.0)\n",
    "spectrogram = contrib_audio.audio_spectrogram(\n",
    "  clamped,\n",
    "  window_size=window_size_samples,\n",
    "  stride=window_stride_samples,\n",
    "  magnitude_squared=magnitude_squared)\n",
    "mfcc = contrib_audio.mfcc(\n",
    "  spectrogram,\n",
    "  wav_decoder.sample_rate,\n",
    "  dct_coefficient_count=dct_coefficient_count)\n",
    "\n",
    "def load_spectrogram(fn):\n",
    "    with tf.Session() as sess:\n",
    "        spectrogram_val = sess.run(\n",
    "            spectrogram, {wav_filename_placeholder: fn})\n",
    "    return spectrogram_val\n",
    "\n",
    "def load_mfcc(fn):\n",
    "    with tf.Session() as sess:\n",
    "        mfcc_val = sess.run(\n",
    "            mfcc, {wav_filename_placeholder: fn})\n",
    "    return mfcc_val\n",
    "\n",
    "def plot_show(label='stop', output='spec', max_disp=3):\n",
    "    fns = sorted(glob('data/train/audio/%s/*.wav' % label))\n",
    "    disp_count = 0\n",
    "    some_data = None\n",
    "    for fn in fns:\n",
    "        if disp_count >= max_disp:\n",
    "            break\n",
    "        if np.random.rand() > 0.9:\n",
    "            if output == 'spec':\n",
    "                spec = load_spectrogram(fn).squeeze()\n",
    "                some_data = spec\n",
    "            elif output == 'mfcc':\n",
    "                mfcc = load_mfcc(fn).squeeze()\n",
    "                some_data = mfcc\n",
    "            plt.figure()\n",
    "            plt.title(fn)\n",
    "            plt.imshow(some_data.T)\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "            disp_count += 1\n",
    "    return some_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_spec = plot_show('sheila', output='spec')\n",
    "print(some_spec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_mfcc = plot_show('stop', output='mfcc', max_disp=3)\n",
    "print(some_mfcc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Time steps: ', (16000 - 480) / 160 + 1)\n",
    "print('Frequencies: ', 16000 / 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??contrib_audio.audio_spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we create a model that does the same? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filter = 257\n",
    "\n",
    "input_layer = Input(shape=[16000])\n",
    "x = input_layer\n",
    "x = Reshape([16000, 1])(x)\n",
    "x = Conv1D(num_filter, window_size_samples, strides=window_stride_samples)(x)\n",
    "model = Model(input_layer, x)\n",
    "\n",
    "def plot_show(model, label='stop'):\n",
    "    fns = sorted(glob('data/train/audio/%s/*.wav' % label))\n",
    "    disp_count = 0\n",
    "    some_spec = None\n",
    "    for fn in fns:\n",
    "        if disp_count > 2:\n",
    "            break\n",
    "        if np.random.rand() > 0.0:\n",
    "            rate, data = wf.read(fn)\n",
    "            data = np.float32(data) / 32768\n",
    "            data = pad_crop(data)\n",
    "            spec = model.predict(data.reshape((1, -1))).squeeze()\n",
    "            some_spec = spec\n",
    "            print(spec.shape)\n",
    "            plt.figure()\n",
    "            plt.title(fn)\n",
    "            plt.imshow(spec.T)\n",
    "            plt.show()\n",
    "            disp_count += 1\n",
    "    return some_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = plot_show(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How about a real trained network? This one gets 94% train accuracy and 89% mean validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('checkpoints_069/ep-060-vl-0.3702.hdf5',\n",
    "                 custom_objects={'relu6': relu6,\n",
    "                                 'DepthwiseConv2D': DepthwiseConv2D})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Concatenate\n",
    "concat_layers = [l for l in model.layers if l.__class__ == Concatenate]\n",
    "print(concat_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = model.layers[3].output\n",
    "# activation = concat_layers[0].output\n",
    "spec_model = Model(model.input, activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    return (x - x.mean()) / x.std()\n",
    "\n",
    "fns = sorted(glob('data/train/audio/go/*.wav'))\n",
    "np.random.shuffle(fns)\n",
    "disp_count = 0\n",
    "for fn in fns:\n",
    "    if disp_count > 2:\n",
    "        break\n",
    "    rate, data = wf.read(fn)\n",
    "    data = np.float32(data) / 32768\n",
    "    data = pad_crop(data)\n",
    "    representation = spec_model.predict(data.reshape((1, -1))).squeeze()\n",
    "    spec = load_spectrogram(fn).squeeze()\n",
    "    spec, representation = norm(spec), norm(representation)\n",
    "    print(spec.shape)\n",
    "    plt.figure()\n",
    "    plt.title(fn)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(representation.T)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(spec.T)\n",
    "    plt.show()\n",
    "    print(representation.shape)\n",
    "    disp_count += 1\n",
    "print(activation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looks like we succesfully decorrelated the channels. Though, it seems like this is not what we really want? There shoud be some relation between groups at least -> Use group convolutions? (g-Sub-seperable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same thing with g-Sub-seperable\n",
    "model = load_model('checkpoints_071/ep-015-vl-0.4296.hdf5',\n",
    "                 custom_objects={'relu6': relu6,\n",
    "                                 'DepthwiseConv2D': DepthwiseConv2D})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Concatenate\n",
    "concat_layers = [l for l in model.layers if l.__class__ == Concatenate]\n",
    "print(concat_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = model.layers[3].output\n",
    "# activation = concat_layers[0].output\n",
    "spec_model = Model(model.input, activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    return (x - x.mean()) / x.std()\n",
    "\n",
    "fns = sorted(glob('data/train/audio/stop/*.wav'))\n",
    "np.random.shuffle(fns)\n",
    "disp_count = 0\n",
    "for fn in fns:\n",
    "    if disp_count > 2:\n",
    "        break\n",
    "    rate, data = wf.read(fn)\n",
    "    data = np.float32(data) / 32768\n",
    "    data = pad_crop(data)\n",
    "    representation = spec_model.predict(data.reshape((1, -1))).squeeze()\n",
    "    spec = load_spectrogram(fn).squeeze()\n",
    "    spec, representation = norm(spec), norm(representation)\n",
    "    print(spec.shape)\n",
    "    plt.figure()\n",
    "    plt.title(fn)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(np.flipud(representation.T))\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(spec.T)\n",
    "    plt.show()\n",
    "    print(representation.shape)\n",
    "    disp_count += 1\n",
    "# print(activation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What representation is actually learned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'checkpoints_069/ep-073-vl-0.3997.hdf5'\n",
    "model = my_load_model('checkpoints_069/ep-073-vl-0.3997.hdf5')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 3  # 4\n",
    "first_layer_weights = model.layers[layer_idx].get_weights()[0].squeeze()\n",
    "first_layer_biases = model.layers[layer_idx].get_weights()[1]\n",
    "# first_layer_weights = model.layers[layer_idx].get_weights()[0].squeeze()\n",
    "# first_layer_weights = first_layer_weights.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_layer_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in first_layer_weights:\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(w)), w)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(first_layer_weights.T, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.dot(first_layer_weights.T, first_layer_weights)\n",
    "plt.imshow(corr, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same for the reshape architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_load_model('checkpoints_084/ep-087-vl-0.2358.hdf5')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 4\n",
    "first_layer_weights = model.layers[layer_idx].get_weights()[0].squeeze()\n",
    "print(first_layer_weights.shape)\n",
    "plt.figure()\n",
    "plt.imshow(first_layer_weights.T, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_label = 'right'\n",
    "test_fns = sorted(glob('data/train/audio/%s/*.wav' % example_label))\n",
    "int2label = get_int2label(wanted_only=False)\n",
    "num_correct = 0\n",
    "num_total = len(test_fns)\n",
    "vis = True\n",
    "pbar = tqdm(test_fns) if not vis else test_fns\n",
    "for fn in pbar:\n",
    "    rate, data = wf.read(fn)\n",
    "    data = pad_crop(data)\n",
    "    data = np.float32(data) / 32767\n",
    "    prediction = model.predict(data.reshape(1, -1)).squeeze()\n",
    "    label = int2label[prediction.argmax()]\n",
    "    if label != example_label and vis:\n",
    "        print(\"Pred: \", label)\n",
    "        display(Audio(fn, autoplay=True))\n",
    "        sleep(1)\n",
    "    \n",
    "    if label == example_label:\n",
    "        num_correct += 1\n",
    "print(\"Acc: %.3f\" % (float(num_correct) / num_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_model = Model(model.input, model.layers[40].output)\n",
    "print(activation_model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "test_fns = sorted(glob('data/train/audio/stop/*.wav'))\n",
    "int2label = get_int2label(wanted_only=False)\n",
    "for i in range(2):\n",
    "    for fn in [test_fns[np.random.randint(len(test_fns))]]:\n",
    "        print(fn)\n",
    "        rate, data = wf.read(fn)\n",
    "        data = pad_crop(data)\n",
    "        data = np.float32(data) / 32767\n",
    "        act_val = activation_model.predict(data.reshape(1, -1)).squeeze()\n",
    "        print(act_val.min(), act_val.max())\n",
    "        display(Audio(fn, autoplay=True))\n",
    "        plt.figure()\n",
    "        plt.subplot(4, 1, 1)\n",
    "        plt.imshow(cv2.resize(act_val.T, (16000, act_val.shape[0] * 20), interpolation=cv2.INTER_NEAREST))\n",
    "        plt.subplot(4, 1, 2)\n",
    "        plt.plot(data)\n",
    "        plt.subplot(4, 1, 3)\n",
    "        corr_mat = np.dot(act_val, act_val.T)\n",
    "        print(corr_mat.shape)\n",
    "        plt.imshow(cv2.resize(corr_mat, (16000, corr_mat.shape[0] * 20), interpolation=cv2.INTER_NEAREST))\n",
    "        plt.colorbar()\n",
    "        plt.subplot(4, 1, 4)\n",
    "        plt.plot(data[::40])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(16000)\n",
    "print(a.reshape((400, 40)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There are a few wrong labels in the training data. Can we find them using ML?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best single model\n",
    "model = my_load_model('checkpoints_086/ep-110-vl-0.1935.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fns = sorted(glob('data/train/audio/*/*.wav'))\n",
    "train_fns = [fn for fn in train_fns\n",
    "             if fn.split('/')[-2] != '_background_noise_' and\n",
    "             fn.split('/')[-2] != 'unknown_unknown']\n",
    "print(\"Found: %d fns\" % len(train_fns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2label = get_int2label(wanted_only=False)\n",
    "fns, preds, gts = [], [], []\n",
    "for fn in tqdm(train_fns[:]):\n",
    "    rate, data = wf.read(fn)\n",
    "    if len(data) != 16000:\n",
    "        data = pad_crop(data)\n",
    "    data = np.float32(data) / 32768\n",
    "    pred = model.predict(data.reshape((1, -1))).squeeze()\n",
    "    gt_label = fn.split('/')[-2]\n",
    "    pred_label = int2label[pred.argmax()]\n",
    "    if pred_label != gt_label:\n",
    "        fns.append(fn)\n",
    "        preds.append(pred_label)\n",
    "        gts.append(gt_label)\n",
    "\n",
    "pd.DataFrame({'filename': fns,\n",
    "              'predicted_label': preds,\n",
    "              'gt_label': gts}).to_csv('wrong_train_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l wrong_train_labels.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_labels = pd.read_csv('wrong_train_labels.csv')\n",
    "print(wrong_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(wrong_labels.shape[0]):\n",
    "    fn = wrong_labels.loc[i, 'filename']\n",
    "    gt = wrong_labels.loc[i, 'gt_label']\n",
    "    pred = wrong_labels.loc[i, 'predicted_label']\n",
    "    if gt == 'stop':\n",
    "        print(\"%s: GT: %s, PRED: %s\" % (fn, gt, pred))\n",
    "        display(Audio(fn, autoplay=True))\n",
    "        sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we speed down the command? This is how I'd repeat something if a person doesn't unterstand me :P (probably louder as well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fns = sorted(glob('data/train/audio/*/*.wav'))\n",
    "print(len(train_fns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "fn = np.random.choice(train_fns)\n",
    "print(fn)\n",
    "rate, data = wf.read(fn)\n",
    "if len(data) != 16000:\n",
    "    data = pad_crop(data)\n",
    "data = np.float32(data) / 32767\n",
    "float_audio(data, autoplay=True)\n",
    "print(data.shape)\n",
    "plt.figure()\n",
    "plt.plot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2? lol: https://www.kaggle.com/haqishen/augmentation-methods-for-audio\n",
    "# The pitch chanes (sounds bad!)\n",
    "speed_rate = 0.8\n",
    "w = int(len(data) / speed_rate)\n",
    "print(w)\n",
    "data_fast = data.reshape((1, -1))\n",
    "data_fast = cv2.resize(\n",
    "    data_fast, (w, 1)).squeeze()\n",
    "data_fast = data_fast[4000: 20000]\n",
    "float_audio(data_fast, autoplay=True)\n",
    "plt.figure()\n",
    "plt.plot(data_fast)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the same with librosa\n",
    "### That sounds good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_crop(data, desired_size=16000):\n",
    "    left = (len(data) - desired_size) // 2\n",
    "    return data[left: left + desired_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "speed = 1.3  # float: < 1.0: slow down, > 1.0: speed up\n",
    "data_fast = lr.effects.time_stretch(data, speed)\n",
    "print(data_fast.shape)\n",
    "# data_fast = data_fast[4000: 20000]\n",
    "float_audio(data_fast, autoplay=True)\n",
    "plt.figure()\n",
    "plt.plot(data_fast)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the attention model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 16000)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 800, 40)      0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 399, 64)      7680        lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 399, 64)      256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 399, 64)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1, 399, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_1 (DepthwiseCo (None, 1, 399, 64)   192         lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 399, 64)      0           depthwise_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 399, 128)     8192        lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 399, 128)     512         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 399, 128)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1, 399, 128)  0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_2 (DepthwiseCo (None, 1, 399, 128)  384         lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 399, 128)     0           depthwise_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 399, 128)     16384       lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 399, 128)     512         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 399, 128)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 200, 128)     8192        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 200, 128)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 200, 128)     512         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 200, 128)     0           max_pooling1d_1[0][0]            \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1, 200, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_3 (DepthwiseCo (None, 1, 200, 128)  384         lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 200, 128)     0           depthwise_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 200, 256)     32768       lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 200, 256)     1024        conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 200, 256)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1, 200, 256)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_4 (DepthwiseCo (None, 1, 200, 256)  768         lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 200, 256)     0           depthwise_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 200, 256)     65536       lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 200, 256)     1024        conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 200, 256)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 100, 256)     32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 100, 256)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 100, 256)     1024        conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 100, 256)     0           max_pooling1d_2[0][0]            \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1, 100, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_5 (DepthwiseCo (None, 1, 100, 256)  768         lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 100, 256)     65536       lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 100, 256)     1024        conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 100, 256)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1, 100, 256)  0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_6 (DepthwiseCo (None, 1, 100, 256)  768         lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 100, 256)     65536       lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 100, 256)     1024        conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 100, 256)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 100, 256)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 100, 256)     0           max_pooling1d_3[0][0]            \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 1, 100, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_7 (DepthwiseCo (None, 1, 100, 256)  768         lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 100, 256)     65536       lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 100, 256)     1024        conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 100, 256)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 1, 100, 256)  0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_8 (DepthwiseCo (None, 1, 100, 256)  768         lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 100, 256)     65536       lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 100, 256)     1024        conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 100, 256)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 100, 256)     0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 100, 256)     0           max_pooling1d_4[0][0]            \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 1, 100, 256)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_9 (DepthwiseCo (None, 1, 100, 256)  768         lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 100, 256)     65536       lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 100, 256)     1024        conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 100, 256)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 1, 100, 256)  0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_10 (DepthwiseC (None, 1, 100, 256)  768         lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 100, 256)     65536       lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 100, 256)     1024        conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 100, 256)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 100, 256)     0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 100, 256)     0           max_pooling1d_5[0][0]            \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 1, 100, 256)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_11 (DepthwiseC (None, 1, 100, 256)  768         lambda_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 100, 256)     65536       lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 100, 256)     1024        conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 100, 256)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 1, 100, 256)  0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_12 (DepthwiseC (None, 1, 100, 256)  768         lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 100, 256)     65536       lambda_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 100, 256)     1024        conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 100, 256)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 100, 256)     0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 100, 256)     0           max_pooling1d_6[0][0]            \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 1, 100, 256)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_13 (DepthwiseC (None, 1, 100, 256)  768         lambda_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 100, 256)     65536       lambda_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 100, 256)     1024        conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 100, 256)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 1, 100, 256)  0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_14 (DepthwiseC (None, 1, 100, 256)  768         lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 100, 256)     65536       lambda_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 100, 256)     1024        conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 100, 256)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 100, 256)     0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 100, 256)     0           max_pooling1d_7[0][0]            \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 1, 100, 256)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_15 (DepthwiseC (None, 1, 100, 256)  768         lambda_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 100, 256)     65536       lambda_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 100, 256)     1024        conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 100, 256)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 1, 100, 256)  0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_16 (DepthwiseC (None, 1, 100, 256)  768         lambda_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 100, 256)     65536       lambda_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 100, 256)     1024        conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 100, 256)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 100, 256)     0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 100, 256)     0           max_pooling1d_8[0][0]            \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 1, 100, 256)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_17 (DepthwiseC (None, 1, 100, 256)  768         lambda_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 100, 256)     65536       lambda_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 100, 256)     1024        conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 100, 256)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)              (None, 1, 100, 256)  0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_18 (DepthwiseC (None, 1, 100, 256)  768         lambda_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 100, 256)     65536       lambda_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 100, 256)     1024        conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 100, 256)     0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 100, 256)     0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 100, 256)     0           max_pooling1d_9[0][0]            \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 1, 100, 256)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_19 (DepthwiseC (None, 1, 100, 256)  768         lambda_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 100, 256)     65536       lambda_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 100, 256)     1024        conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 100, 256)     0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 1, 100, 256)  0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_20 (DepthwiseC (None, 1, 100, 256)  768         lambda_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 100, 256)     65536       lambda_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 100, 256)     1024        conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 100, 256)     0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 100, 256)     0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 100, 256)     0           max_pooling1d_10[0][0]           \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 1, 100, 256)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_21 (DepthwiseC (None, 1, 100, 256)  768         lambda_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 100, 384)     98304       lambda_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 100, 384)     1536        conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 100, 384)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 1, 100, 384)  0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_22 (DepthwiseC (None, 1, 100, 384)  1152        lambda_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)              (None, 100, 384)     0           depthwise_conv2d_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 100, 384)     147456      lambda_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 100, 384)     1536        conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 100, 384)     0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 50, 384)      98304       add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 50, 384)      0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 50, 384)      1536        conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 50, 384)      0           max_pooling1d_11[0][0]           \n",
      "                                                                 batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 1, 50, 384)   0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_23 (DepthwiseC (None, 1, 50, 384)   1152        lambda_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None, 50, 384)      0           depthwise_conv2d_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 50, 512)      196608      lambda_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 50, 512)      2048        conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 50, 512)      0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 1, 50, 512)   0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_24 (DepthwiseC (None, 1, 50, 512)   1536        lambda_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)              (None, 50, 512)      0           depthwise_conv2d_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 50, 512)      262144      lambda_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 50, 512)      2048        conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 50, 512)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 25, 512)      196608      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 25, 512)      0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 25, 512)      2048        conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 25, 512)      0           max_pooling1d_12[0][0]           \n",
      "                                                                 batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)              (None, 1, 25, 512)   0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_25 (DepthwiseC (None, 1, 25, 512)   1536        lambda_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)              (None, 25, 512)      0           depthwise_conv2d_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 25, 728)      372736      lambda_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 25, 728)      2912        conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 25, 728)      0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)              (None, 1, 25, 728)   0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_26 (DepthwiseC (None, 1, 25, 728)   2184        lambda_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)              (None, 25, 728)      0           depthwise_conv2d_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 25, 728)      529984      lambda_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 25, 728)      2912        conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 25, 728)      0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 13, 728)      372736      add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 13, 728)      0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 13, 728)      2912        conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 13, 728)      0           max_pooling1d_13[0][0]           \n",
      "                                                                 batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 13, 1)        728         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 13, 728)      0           add_13[0][0]                     \n",
      "                                                                 conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 728)          0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 728)          0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           23328       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,582,112\n",
      "Trainable params: 3,561,744\n",
      "Non-trainable params: 20,368\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = my_load_model('checkpoints_104/ep-099-vl-0.2038.hdf5')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 13, 1)\n"
     ]
    }
   ],
   "source": [
    "attention = Model(model.input, model.layers[-5].output)\n",
    "print(attention.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test/audio/clip_000044442.wav\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDRl3SWro/wGhDC/mSvpZdQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9355c182b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test/audio/clip_0000adecb.wav\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADYxJREFUeJzt3H+s3Xddx/Hni5bJgLmpuxJoK1tiQZsF3byZ0yVKHCTd\nJK2JxqxxCrrQfxhOXTQjmGlmYkAM/ogTrPwY4tysE7XR4iAwQ2IY2R3DubYObgautwx3+eE0LjIa\n3/5xzsjh0vZ+b+9pz+47z0fS9Hy/55Nz3t/s7tnv/Z4fqSokSb08Z9YDSJKmz7hLUkPGXZIaMu6S\n1JBxl6SGjLskNbRq3JO8J8kTSR4+yf1J8odJFpM8lOSy6Y8pSVqLIWfutwM7T3H/1cD28Z+9wDvW\nP5YkaT1WjXtVfQz48imW7Ab+rEbuAy5I8uJpDShJWrvNU3iMLcDRie2l8b7HVy5MspfR2T2bzz3v\nB86b2zKFp5ek2XveOc/hJeefe8af54EHHvhiVc2ttm4acR+sqvYB+wDm5+drYWHhbD69JG14Sf59\nyLppvFvmGLBtYnvreJ8kaUamEfcDwM+N3zVzBfBkVX3TJRlJ0tmz6mWZJHcCrwQuTLIE/AbwXICq\neidwELgGWASeAn7+TA0rSRpm1bhX1Z5V7i/gDVObSJK0bn5CVZIaMu6S1JBxl6SGjLskNWTcJakh\n4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQ\ncZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrI\nuEtSQ8Zdkhoy7pLUkHGXpIYGxT3JziSPJFlMcvMJ7v+uJPcmeTDJQ0mumf6okqShVo17kk3AbcDV\nwA5gT5IdK5b9OrC/qi4FrgX+eNqDSpKGG3LmfjmwWFWPVtXTwF3A7hVrCvjW8e3zgc9Pb0RJ0loN\nifsW4OjE9tJ436TfBK5LsgQcBN54ogdKsjfJQpKF5eXl0xhXkjTEtF5Q3QPcXlVbgWuA9yf5pseu\nqn1VNV9V83Nzc1N6aknSSkPifgzYNrG9dbxv0vXAfoCq+jjwPODCaQwoSVq7IXG/H9ie5OIk5zB6\nwfTAijWPAVcBJPleRnH3uoskzciqca+q48ANwD3AEUbvijmU5NYku8bLbgJen+RfgDuB11VVnamh\nJUmntnnIoqo6yOiF0sl9t0zcPgxcOd3RJEmny0+oSlJDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMu\nSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGX\npIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhL\nUkPGXZIaGhT3JDuTPJJkMcnNJ1nz00kOJzmU5C+mO6YkaS02r7YgySbgNuDVwBJwf5IDVXV4Ys12\n4E3AlVX1lSTfeaYGliStbsiZ++XAYlU9WlVPA3cBu1eseT1wW1V9BaCqnpjumJKktRgS9y3A0Ynt\npfG+SS8DXpbkn5Pcl2TniR4oyd4kC0kWlpeXT29iSdKqpvWC6mZgO/BKYA/wp0kuWLmoqvZV1XxV\nzc/NzU3pqSVJKw2J+zFg28T21vG+SUvAgar6WlV9Fvg0o9hLkmZgSNzvB7YnuTjJOcC1wIEVa/6W\n0Vk7SS5kdJnm0SnOKUlag1XjXlXHgRuAe4AjwP6qOpTk1iS7xsvuAb6U5DBwL/CrVfWlMzW0JOnU\nUlUzeeL5+flaWFiYyXNL0kaV5IGqml9tnZ9QlaSGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy\n7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Z\nd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaM\nuyQ1ZNwlqaFBcU+yM8kjSRaT3HyKdT+ZpJLMT29ESdJarRr3JJuA24CrgR3AniQ7TrDuPOBG4BPT\nHlKStDZDztwvBxar6tGqehq4C9h9gnW/BbwV+N8pzidJOg1D4r4FODqxvTTe93VJLgO2VdU/nOqB\nkuxNspBkYXl5ec3DSpKGWfcLqkmeA7wduGm1tVW1r6rmq2p+bm5uvU8tSTqJIXE/Bmyb2N463veM\n84BLgH9K8jngCuCAL6pK0uwMifv9wPYkFyc5B7gWOPDMnVX1ZFVdWFUXVdVFwH3ArqpaOCMTS5JW\ntWrcq+o4cANwD3AE2F9Vh5LcmmTXmR5QkrR2m4csqqqDwMEV+245ydpXrn8sSdJ6+AlVSWrIuEtS\nQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWp\nIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLU\nkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDg+KeZGeSR5IsJrn5BPf/SpLDSR5K8pEkL53+qJKk\noVaNe5JNwG3A1cAOYE+SHSuWPQjMV9UrgLuB35n2oJKk4YacuV8OLFbVo1X1NHAXsHtyQVXdW1VP\njTfvA7ZOd0xJ0loMifsW4OjE9tJ438lcD3zwRHck2ZtkIcnC8vLy8CklSWsy1RdUk1wHzANvO9H9\nVbWvquaran5ubm6aTy1JmrB5wJpjwLaJ7a3jfd8gyauANwM/WlVfnc54kqTTMeTM/X5ge5KLk5wD\nXAscmFyQ5FLgT4BdVfXE9MeUJK3FqnGvquPADcA9wBFgf1UdSnJrkl3jZW8DXgj8VZJPJTlwkoeT\nJJ0FQy7LUFUHgYMr9t0ycftVU55LkrQOfkJVkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4\nS1JDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTc\nJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLu\nktSQcZekhgbFPcnOJI8kWUxy8wnu/5Ykfzm+/xNJLpr2oJKk4VaNe5JNwG3A1cAOYE+SHSuWXQ98\npaq+G/g94K3THlSSNNyQM/fLgcWqerSqngbuAnavWLMbeN/49t3AVUkyvTElSWuxecCaLcDRie0l\n4AdPtqaqjid5EvgO4IuTi5LsBfaON7+a5OHTGfpZ6kJWHO8G1ulYoNfxdDoW6HU8Z+tYXjpk0ZC4\nT01V7QP2ASRZqKr5s/n8Z1Kn4+l0LNDreDodC/Q6nmfbsQy5LHMM2DaxvXW874RrkmwGzge+NI0B\nJUlrNyTu9wPbk1yc5BzgWuDAijUHgNeOb/8U8NGqqumNKUlai1Uvy4yvod8A3ANsAt5TVYeS3Aos\nVNUB4N3A+5MsAl9m9A/AavatY+5no07H0+lYoNfxdDoW6HU8z6pjiSfYktSPn1CVpIaMuyQ1NJO4\nr/Z1BhtFkm1J7k1yOMmhJDfOeqb1SrIpyYNJ/n7Ws6xXkguS3J3k35IcSfJDs55pPZL88vjn7OEk\ndyZ53qxnGirJe5I8MfnZliTfnuTDST4z/vvbZjnjWpzkeN42/ll7KMnfJLlgljOe9bgP/DqDjeI4\ncFNV7QCuAN6wgY/lGTcCR2Y9xJT8AfCPVfU9wPexgY8ryRbgF4H5qrqE0Zsbhrxx4dnidmDnin03\nAx+pqu3AR8bbG8XtfPPxfBi4pKpeAXwaeNPZHmrSLM7ch3ydwYZQVY9X1SfHt/+bUTy2zHaq05dk\nK/DjwLtmPct6JTkf+BFG7+Siqp6uqv+c7VTrthk4d/xZkucDn5/xPINV1ccYvZNu0uTXlrwP+Imz\nOtQ6nOh4qupDVXV8vHkfo88Ezcws4n6irzPYsEF8xvibMC8FPjHbSdbl94FfA/5v1oNMwcXAMvDe\n8WWmdyV5wayHOl1VdQz4XeAx4HHgyar60GynWrcXVdXj49tfAF40y2Gm7BeAD85yAF9QnYIkLwT+\nGvilqvqvWc9zOpK8Bniiqh6Y9SxTshm4DHhHVV0K/A8b69f+bzC+Hr2b0T9aLwFekOS62U41PeMP\nPbZ4X3aSNzO6ZHvHLOeYRdyHfJ3BhpHkuYzCfkdVfWDW86zDlcCuJJ9jdKnsx5L8+WxHWpclYKmq\nnvlN6m5Gsd+oXgV8tqqWq+prwAeAH57xTOv1H0leDDD++4kZz7NuSV4HvAb4mVl/Sn8WcR/ydQYb\nwvhrjd8NHKmqt896nvWoqjdV1daquojRf5OPVtWGPTOsqi8AR5O8fLzrKuDwDEdar8eAK5I8f/xz\ndxUb+AXiscmvLXkt8HcznGXdkuxkdFlzV1U9Net5znrcxy84PPN1BkeA/VV16GzPMSVXAj/L6Cz3\nU+M/18x6KH3dG4E7kjwEfD/w2zOe57SNfwO5G/gk8K+M/t99Vn3c/VSS3Al8HHh5kqUk1wNvAV6d\n5DOMfjN5yyxnXIuTHM8fAecBHx634J0zndGvH5CkfnxBVZIaMu6S1JBxl6SGjLskNWTcJakh4y5J\nDRl3SWro/wGhDC/mSvpZdQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f93549e00f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test/audio/clip_0000d4322.wav\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADYxJREFUeJzt3H+s3Xddx/Hni5bJgLmpuxJoK1tiQZsF3byZ0yVKHCTd\nJK2JxqxxCrrQfxhOXTQjmGlmYkAM/ogTrPwY4tysE7XR4iAwQ2IY2R3DubYObgautwx3+eE0LjIa\n3/5xzsjh0vZ+b+9pz+47z0fS9Hy/55Nz3t/s7tnv/Z4fqSokSb08Z9YDSJKmz7hLUkPGXZIaMu6S\n1JBxl6SGjLskNbRq3JO8J8kTSR4+yf1J8odJFpM8lOSy6Y8pSVqLIWfutwM7T3H/1cD28Z+9wDvW\nP5YkaT1WjXtVfQz48imW7Ab+rEbuAy5I8uJpDShJWrvNU3iMLcDRie2l8b7HVy5MspfR2T2bzz3v\nB86b2zKFp5ek2XveOc/hJeefe8af54EHHvhiVc2ttm4acR+sqvYB+wDm5+drYWHhbD69JG14Sf59\nyLppvFvmGLBtYnvreJ8kaUamEfcDwM+N3zVzBfBkVX3TJRlJ0tmz6mWZJHcCrwQuTLIE/AbwXICq\neidwELgGWASeAn7+TA0rSRpm1bhX1Z5V7i/gDVObSJK0bn5CVZIaMu6S1JBxl6SGjLskNWTcJakh\n4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQ\ncZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrI\nuEtSQ8Zdkhoy7pLUkHGXpIYGxT3JziSPJFlMcvMJ7v+uJPcmeTDJQ0mumf6okqShVo17kk3AbcDV\nwA5gT5IdK5b9OrC/qi4FrgX+eNqDSpKGG3LmfjmwWFWPVtXTwF3A7hVrCvjW8e3zgc9Pb0RJ0loN\nifsW4OjE9tJ436TfBK5LsgQcBN54ogdKsjfJQpKF5eXl0xhXkjTEtF5Q3QPcXlVbgWuA9yf5pseu\nqn1VNV9V83Nzc1N6aknSSkPifgzYNrG9dbxv0vXAfoCq+jjwPODCaQwoSVq7IXG/H9ie5OIk5zB6\nwfTAijWPAVcBJPleRnH3uoskzciqca+q48ANwD3AEUbvijmU5NYku8bLbgJen+RfgDuB11VVnamh\nJUmntnnIoqo6yOiF0sl9t0zcPgxcOd3RJEmny0+oSlJDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMu\nSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGX\npIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhL\nUkPGXZIaGhT3JDuTPJJkMcnNJ1nz00kOJzmU5C+mO6YkaS02r7YgySbgNuDVwBJwf5IDVXV4Ys12\n4E3AlVX1lSTfeaYGliStbsiZ++XAYlU9WlVPA3cBu1eseT1wW1V9BaCqnpjumJKktRgS9y3A0Ynt\npfG+SS8DXpbkn5Pcl2TniR4oyd4kC0kWlpeXT29iSdKqpvWC6mZgO/BKYA/wp0kuWLmoqvZV1XxV\nzc/NzU3pqSVJKw2J+zFg28T21vG+SUvAgar6WlV9Fvg0o9hLkmZgSNzvB7YnuTjJOcC1wIEVa/6W\n0Vk7SS5kdJnm0SnOKUlag1XjXlXHgRuAe4AjwP6qOpTk1iS7xsvuAb6U5DBwL/CrVfWlMzW0JOnU\nUlUzeeL5+flaWFiYyXNL0kaV5IGqml9tnZ9QlaSGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy\n7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Z\nd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaM\nuyQ1ZNwlqaFBcU+yM8kjSRaT3HyKdT+ZpJLMT29ESdJarRr3JJuA24CrgR3AniQ7TrDuPOBG4BPT\nHlKStDZDztwvBxar6tGqehq4C9h9gnW/BbwV+N8pzidJOg1D4r4FODqxvTTe93VJLgO2VdU/nOqB\nkuxNspBkYXl5ec3DSpKGWfcLqkmeA7wduGm1tVW1r6rmq2p+bm5uvU8tSTqJIXE/Bmyb2N463veM\n84BLgH9K8jngCuCAL6pK0uwMifv9wPYkFyc5B7gWOPDMnVX1ZFVdWFUXVdVFwH3ArqpaOCMTS5JW\ntWrcq+o4cANwD3AE2F9Vh5LcmmTXmR5QkrR2m4csqqqDwMEV+245ydpXrn8sSdJ6+AlVSWrIuEtS\nQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLuktSQcZekhoy7JDVk3CWp\nIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTcJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLU\nkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDg+KeZGeSR5IsJrn5BPf/SpLDSR5K8pEkL53+qJKk\noVaNe5JNwG3A1cAOYE+SHSuWPQjMV9UrgLuB35n2oJKk4YacuV8OLFbVo1X1NHAXsHtyQVXdW1VP\njTfvA7ZOd0xJ0loMifsW4OjE9tJ438lcD3zwRHck2ZtkIcnC8vLy8CklSWsy1RdUk1wHzANvO9H9\nVbWvquaran5ubm6aTy1JmrB5wJpjwLaJ7a3jfd8gyauANwM/WlVfnc54kqTTMeTM/X5ge5KLk5wD\nXAscmFyQ5FLgT4BdVfXE9MeUJK3FqnGvquPADcA9wBFgf1UdSnJrkl3jZW8DXgj8VZJPJTlwkoeT\nJJ0FQy7LUFUHgYMr9t0ycftVU55LkrQOfkJVkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4\nS1JDxl2SGjLuktSQcZekhoy7JDVk3CWpIeMuSQ0Zd0lqyLhLUkPGXZIaMu6S1JBxl6SGjLskNWTc\nJakh4y5JDRl3SWrIuEtSQ8Zdkhoy7pLUkHGXpIaMuyQ1ZNwlqSHjLkkNGXdJasi4S1JDxl2SGjLu\nktSQcZekhgbFPcnOJI8kWUxy8wnu/5Ykfzm+/xNJLpr2oJKk4VaNe5JNwG3A1cAOYE+SHSuWXQ98\npaq+G/g94K3THlSSNNyQM/fLgcWqerSqngbuAnavWLMbeN/49t3AVUkyvTElSWuxecCaLcDRie0l\n4AdPtqaqjid5EvgO4IuTi5LsBfaON7+a5OHTGfpZ6kJWHO8G1ulYoNfxdDoW6HU8Z+tYXjpk0ZC4\nT01V7QP2ASRZqKr5s/n8Z1Kn4+l0LNDreDodC/Q6nmfbsQy5LHMM2DaxvXW874RrkmwGzge+NI0B\nJUlrNyTu9wPbk1yc5BzgWuDAijUHgNeOb/8U8NGqqumNKUlai1Uvy4yvod8A3ANsAt5TVYeS3Aos\nVNUB4N3A+5MsAl9m9A/AavatY+5no07H0+lYoNfxdDoW6HU8z6pjiSfYktSPn1CVpIaMuyQ1NJO4\nr/Z1BhtFkm1J7k1yOMmhJDfOeqb1SrIpyYNJ/n7Ws6xXkguS3J3k35IcSfJDs55pPZL88vjn7OEk\ndyZ53qxnGirJe5I8MfnZliTfnuTDST4z/vvbZjnjWpzkeN42/ll7KMnfJLlgljOe9bgP/DqDjeI4\ncFNV7QCuAN6wgY/lGTcCR2Y9xJT8AfCPVfU9wPexgY8ryRbgF4H5qrqE0Zsbhrxx4dnidmDnin03\nAx+pqu3AR8bbG8XtfPPxfBi4pKpeAXwaeNPZHmrSLM7ch3ydwYZQVY9X1SfHt/+bUTy2zHaq05dk\nK/DjwLtmPct6JTkf+BFG7+Siqp6uqv+c7VTrthk4d/xZkucDn5/xPINV1ccYvZNu0uTXlrwP+Imz\nOtQ6nOh4qupDVXV8vHkfo88Ezcws4n6irzPYsEF8xvibMC8FPjHbSdbl94FfA/5v1oNMwcXAMvDe\n8WWmdyV5wayHOl1VdQz4XeAx4HHgyar60GynWrcXVdXj49tfAF40y2Gm7BeAD85yAF9QnYIkLwT+\nGvilqvqvWc9zOpK8Bniiqh6Y9SxTshm4DHhHVV0K/A8b69f+bzC+Hr2b0T9aLwFekOS62U41PeMP\nPbZ4X3aSNzO6ZHvHLOeYRdyHfJ3BhpHkuYzCfkdVfWDW86zDlcCuJJ9jdKnsx5L8+WxHWpclYKmq\nnvlN6m5Gsd+oXgV8tqqWq+prwAeAH57xTOv1H0leDDD++4kZz7NuSV4HvAb4mVl/Sn8WcR/ydQYb\nwvhrjd8NHKmqt896nvWoqjdV1daquojRf5OPVtWGPTOsqi8AR5O8fLzrKuDwDEdar8eAK5I8f/xz\ndxUb+AXiscmvLXkt8HcznGXdkuxkdFlzV1U9Net5znrcxy84PPN1BkeA/VV16GzPMSVXAj/L6Cz3\nU+M/18x6KH3dG4E7kjwEfD/w2zOe57SNfwO5G/gk8K+M/t99Vn3c/VSS3Al8HHh5kqUk1wNvAV6d\n5DOMfjN5yyxnXIuTHM8fAecBHx634J0zndGvH5CkfnxBVZIaMu6S1JBxl6SGjLskNWTcJakh4y5J\nDRl3SWro/wGhDC/mSvpZdQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9355cbdd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test/audio/clip_0000fb6fe.wav\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDRl3SWro/wGhDC/mSvpZdQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9355c43080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_fns = sorted(glob('data/test/audio/*.wav'))\n",
    "disp_count = 0\n",
    "for fn in test_fns:\n",
    "    if disp_count > 3:\n",
    "        break\n",
    "    print(fn)\n",
    "    rate, data = wf.read(fn)\n",
    "    data = np.float32(data) / 32767\n",
    "    data = pad_crop(data)\n",
    "    attention_val = attention.predict(data.reshape((1, -1))).squeeze()\n",
    "    disp_count += 1\n",
    "    print(attention_val)\n",
    "    plt.plot(range(len(attention_val)), attention_val)\n",
    "    plt.axis([0, len(attention_val), 0, 1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
