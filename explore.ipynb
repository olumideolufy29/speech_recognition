{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "from IPython.display import Audio, display\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import librosa as lr\n",
    "import numpy as np\n",
    "import os\n",
    "from shutil import copy, rmtree\n",
    "from os.path import join as jp\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from scipy.io import wavfile as wf\n",
    "from time import time, sleep\n",
    "from input_data import prepare_words_list\n",
    "from glob import glob\n",
    "import hashlib\n",
    "from classes import get_classes, get_int2label, get_label2int\n",
    "from keras.layers import Input, Lambda\n",
    "from model import prepare_model_settings, relu6, overlapping_time_slice_stack\n",
    "from keras.applications.mobilenet import DepthwiseConv2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio\n",
    "from tensorflow.python.ops import io_ops\n",
    "from keras.layers import Input, Conv1D, Reshape\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "def my_load_model(fn):\n",
    "    return load_model(fn, {'relu6': relu6, 'DepthwiseConv2D': DepthwiseConv2D,\n",
    "                           'overlapping_time_slice_stack': overlapping_time_slice_stack})\n",
    "\n",
    "def pad_crop(data, desired_size=16000):\n",
    "    data_len = len(data)\n",
    "    if data_len < desired_size:\n",
    "        missing = desired_size - data_len\n",
    "        data = np.pad(data, (missing, 0), mode='constant')\n",
    "    else:\n",
    "        data = data[:desired_size]\n",
    "    return data\n",
    "\n",
    "def float_audio(x, sample_rate=16000, autoplay=False):\n",
    "    # avoid Audio normalizing the data\n",
    "    data = np.int16(x * 32768)\n",
    "    fn = '/tmp/%s.wav' % data[:5]\n",
    "    wf.write(fn, sample_rate, data)\n",
    "    display(Audio(filename=fn, rate=sample_rate, autoplay=autoplay))\n",
    "\n",
    "def plot_audio(data, sample_rate=16000, normed=False):\n",
    "    if not normed:\n",
    "        data = np.float32(data) / 32768\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(sample_rate), data)\n",
    "    plt.axis([0, sample_rate, -1, 1])\n",
    "    \n",
    "def center_pad(data, desired_size=16000):\n",
    "    missing = desired_size - len(data)\n",
    "    pad_left = missing // 2\n",
    "    pad_right = missing - pad_left\n",
    "    padded_data = np.pad(data, (pad_left, pad_right), mode='constant')\n",
    "    return padded_data\n",
    "\n",
    "def random_crop(data, desired_size=16000):\n",
    "    start = np.random.randint(len(data) - desired_size)\n",
    "    return data[start: start + desired_size]\n",
    "\n",
    "def normalized_read(fn, desired_size=16000):\n",
    "    rate, data = wf.read(fn)\n",
    "    data = np.float32(data) / 32768\n",
    "    assert rate == 16000\n",
    "    if len(data) < desired_size:\n",
    "        data = center_pad(data, desired_size=desired_size)\n",
    "    elif len(data) > desired_size:\n",
    "        data = random_crop(data, desired_size=desired_size)\n",
    "    return data\n",
    "\n",
    "def md5(fname):\n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(fname, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sub1 = pd.read_csv('submission_033b.csv')  # 87% PLB\n",
    "sub2 = pd.read_csv('submission_017.csv')  # 87% PLB\n",
    "sub3 = pd.read_csv('submission_018.csv')  # 86% PLB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check where all three disagree\n",
    "unequal = ((sub1.label != sub2.label) & (sub1.label != sub3.label))\n",
    "print(\"%d of %d are unequal\" % (unequal.sum(), sub1.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display where classifiers disagree\n",
    "These samples are acutally quite hard!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = 'data/test/audio'\n",
    "disp_count = 0\n",
    "for i in range(len(unequal)):\n",
    "    if disp_count > 5:\n",
    "        break\n",
    "    if unequal[i] and np.random.rand() > 0.99:\n",
    "        fn = os.path.join(TEST_DIR, sub1.loc[i, 'fname'])\n",
    "        print(fn, ': ', sub1.loc[i, 'label'], \" vs \", sub2.loc[i, 'label'])\n",
    "        display(Audio(fn, autoplay=True))\n",
    "        sleep(1)\n",
    "        disp_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these \"hard\" ones\n",
    "for i in tqdm(range(len(unequal))):\n",
    "    if unequal[i]:\n",
    "        bn = sub1.loc[i, 'fname']\n",
    "        src_fn = os.path.join('data/test/audio', bn)\n",
    "        dst_fn = os.path.join('data/pseudo/audio/unknown', bn)\n",
    "        copy(src_fn, dst_fn)\n",
    "# when using as pseudo labels remove 'silence'! (e.g. ls *.wav | grep -v silence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show (predicted) test data distribution\n",
    "### Note that during training silence prob was 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_bar(submission):\n",
    "    counts = []\n",
    "    for label_name in submission.label.unique():\n",
    "        label_count = (submission.label == label_name).sum()\n",
    "        percent = (label_count / num_total) * 100.0\n",
    "        counts.append((label_name, percent))\n",
    "    print(counts)\n",
    "    plt.bar(range(len(counts)), [c[-1] for c in counts])\n",
    "    _ = plt.xticks(range(len(counts)), [c[0] for c in counts])\n",
    "    plt.grid('on')\n",
    "    plt.xlabel('Label names')\n",
    "    plt.ylabel('Precentage [%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_bar(sub1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compress and decompress using mu-law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav(fn):\n",
    "    rate, data = wf.read(fn)\n",
    "    assert rate == 16000\n",
    "    data = data / 32768\n",
    "    missing = 16000 - len(data)\n",
    "    data = np.pad(data, (missing, 0), mode='constant')\n",
    "    return data\n",
    "\n",
    "\n",
    "def compress(x, mu=255):\n",
    "    assert x.min() >= -1 and x.max() <= 1\n",
    "    compressed = np.sign(x) * np.log10(1.0 + mu * np.abs(x)) / np.log10(1.0 + mu)\n",
    "    return compressed\n",
    "\n",
    "def decompress(x, mu=255):\n",
    "    assert x.min() >= -1 and x.max() <= 1\n",
    "    decompressed= np.sign(x) * (1.0 / mu) * (np.power(1.0 + x, np.abs(x)) - 1.0)\n",
    "    return decompressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_sample = load_wav('data/test/audio/clip_001204892.wav')\n",
    "float_audio(up_sample)\n",
    "c = compress(up_sample)\n",
    "d = decompress(c)\n",
    "float_audio(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(data=np.int16(up_sample  * 32768), rate=16000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use average pooling to reduce signal size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import AveragePooling1D, Input, Reshape\n",
    "def avg_model(sample_rate=16000):\n",
    "    input_layer = Input([sample_rate])\n",
    "    x = input_layer\n",
    "    x = Reshape([-1, 1])(x)\n",
    "    x = AveragePooling1D(2)(x)\n",
    "    return Model(input_layer, x)\n",
    "\n",
    "model = avg_model()\n",
    "out = model.predict([up_sample.reshape((1, -1))]).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title('Orginal')\n",
    "plt.plot(up_sample)\n",
    "plt.figure()\n",
    "plt.title('Subsamples')\n",
    "plt.plot(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_audio(out, sample_rate=len(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How is the padding handeled by decode_wav?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.framework.python.ops import audio_ops as contrib_audio\n",
    "from tensorflow.python.ops import io_ops\n",
    "\n",
    "wav_filename_placeholder = tf.placeholder(tf.string, [])\n",
    "wav_loader = io_ops.read_file(wav_filename_placeholder)\n",
    "wav_decoder = contrib_audio.decode_wav(\n",
    "    wav_loader, desired_channels=1)\n",
    "fns = sorted(glob('data/train/audio/go/*.wav'))\n",
    "short_fn = ''\n",
    "with tf.Session() as sess:\n",
    "    for fn in fns:\n",
    "        out = sess.run(wav_decoder.audio,\n",
    "                       {wav_filename_placeholder: fn_val})\n",
    "        if out.shape[0] != 16000:\n",
    "            short_fn = fn\n",
    "            print(fn)\n",
    "            break\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Audio(short_fn, autoplay=True))\n",
    "sleep(1)\n",
    "float_audio(out, autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check how many samples are shorter than 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "train_fns = sorted(glob('data/train/audio/*/*.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav(fn):\n",
    "    rate, data = wf.read(fn)\n",
    "    assert rate == 16000\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "short_count = 0\n",
    "for fn in tqdm(train_fns):\n",
    "    data = load_wav(fn)\n",
    "    if len(data) != 16000:\n",
    "        short_count += 1\n",
    "print(\"Short: \", short_count)\n",
    "print(\"All: \", len(train_fns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize augmented training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import TensorBoard\n",
    "from callbacks import ConfusionMatrixCallback\n",
    "from model import speech_model, prepare_model_settings\n",
    "from input_data import AudioProcessor, prepare_words_list\n",
    "from classes import get_classes\n",
    "from IPython import embed  # noqa"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def data_gen(audio_processor, sess,\n",
    "             batch_size=128,\n",
    "             background_frequency=0.5, background_volume_range=0.2,\n",
    "             foreground_frequency=0.5, foreground_volume_range=0.2,\n",
    "             time_shift=(100.0 * 16000.0) / 1000,\n",
    "             mode='validation'):\n",
    "    offset = 0\n",
    "    if mode != 'training':\n",
    "        background_frequency = 0.0\n",
    "        background_volume_range = 0.0\n",
    "        foreground_frequency = 0.0\n",
    "        foreground_volume_range = 0.0\n",
    "        time_shift = 0\n",
    "    while True:\n",
    "        X, y = audio_processor.get_data(\n",
    "            how_many=batch_size, offset=0 if mode == 'training' else offset,\n",
    "            background_frequency=background_frequency,\n",
    "            background_volume_range=background_volume_range,\n",
    "            foreground_frequency=foreground_frequency,\n",
    "            foreground_volume_range=foreground_volume_range,\n",
    "            time_shift=time_shift, mode=mode, sess=sess)\n",
    "        offset += batch_size\n",
    "        if offset > ap.set_size(mode) - batch_size:\n",
    "              offset = 0\n",
    "        yield X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = K.get_session()\n",
    "data_dirs = ['data/train/audio']\n",
    "add_pseudo = True\n",
    "if add_pseudo:\n",
    "    data_dirs.append('data/pseudo/audio')\n",
    "compute_mfcc = False\n",
    "sample_rate = 16000\n",
    "batch_size = 100\n",
    "classes = get_classes(wanted_only=False)\n",
    "model_settings = prepare_model_settings(\n",
    "  label_count=len(prepare_words_list(classes)), sample_rate=sample_rate,\n",
    "  clip_duration_ms=1000, window_size_ms=30.0, window_stride_ms=10.0,\n",
    "  dct_coefficient_count=40)\n",
    "ap = AudioProcessor(\n",
    "  data_dirs=data_dirs,\n",
    "  silence_percentage=10.0,\n",
    "  unknown_percentage=7.0,\n",
    "  wanted_words=classes,\n",
    "  validation_percentage=10.0,\n",
    "  testing_percentage=0.0,\n",
    "  model_settings=model_settings,\n",
    "  compute_mfcc=compute_mfcc)\n",
    "train_gen = data_gen(ap, sess, batch_size=batch_size, mode='training')\n",
    "val_gen = data_gen(ap, sess, batch_size=batch_size, mode='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_count = 0\n",
    "while True:\n",
    "    if disp_count > 5:\n",
    "        break\n",
    "    X, y = next(train_gen)\n",
    "    for i in range(X.shape[0]):\n",
    "        if y[i].argmax() == 10:\n",
    "            sample = X[i, :].squeeze()\n",
    "            float_audio(sample, autoplay=True)\n",
    "            sleep(1)\n",
    "            disp_count += 1\n",
    "            # plt.figure()\n",
    "            # plt.axis([0, 16000, -1, 1])\n",
    "            # plt.plot(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create pseudo labels from consistent predictions\n",
    "### [v_001]: Sub1: 84% PLB, Sub2: 84% PLB, Sub3: 82%: 118078 consistend pseudo labels\n",
    "### [v_002]: Sub1: 87%, Sub2: 87%, Sub3: 88%: 140945 pseudo consistend pseudo labels\n",
    "#### v_002: There are only 158538 test data points! Maybe that's the reason I am stuck -> reduce pseudo label fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1 = pd.read_csv('submission_098_leftloud_tta_all_labels.csv')  # 87% PLB\n",
    "sub2 = pd.read_csv('submission_096_leftloud_tta_all_labels.csv')  # 87% PLB\n",
    "sub3 = pd.read_csv('submission_091_leftloud_tta_all_labels.csv')  # 88% PLB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consistend = ((sub1.label == sub2.label) & (sub1.label == sub3.label))\n",
    "print(\"All: \", sub1.shape[0], \" consistend: \", consistend.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(sub1.shape[0])):\n",
    "    fn = sub1.loc[i, 'fname']\n",
    "    if fn != sub2.loc[i, 'fname'] or fn != sub3.loc[i, 'fname']:\n",
    "        print(\"Fatal error\")\n",
    "        break\n",
    "    if consistend[i]:\n",
    "        label = sub1.loc[i, 'label']\n",
    "        dst_fn = jp('data', 'pseudo', 'audio', label, fn)\n",
    "        src_fn = jp('data', 'test', 'audio', fn)\n",
    "        copy(src_fn, dst_fn, follow_symlinks=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new background noise from pseudo silence\n",
    "## Just concat 60 seconds of audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_silence_fns = sorted(glob('data/pseudo/silence/*.wav'))\n",
    "num_pseudo_noise = 5\n",
    "num_secs = 60\n",
    "for i in range(num_pseudo_noise):\n",
    "    background_fns = np.random.choice(\n",
    "        pseudo_silence_fns, num_secs, replace=False)\n",
    "    new_clip = []\n",
    "    for fn in background_fns:\n",
    "        rate, data = wf.read(fn)\n",
    "        new_clip.append(data)\n",
    "    new_clip = np.concatenate(new_clip).astype(np.int16)\n",
    "    out_fn = 'data/train/audio/_background_noise_/custom_pseudo_silence_%04d.wav' % i\n",
    "    # print(out_fn)\n",
    "    wf.write(out_fn, 16000, new_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?wf.write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listen to submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = get_classes(wanted_only=False, extend_reversed=True)\n",
    "[w for w in words if 'b' in w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('submission_091_all_labels.csv')\n",
    "label2int = get_label2int(wanted_only=True)\n",
    "disp_count = 0\n",
    "for i in reversed(range(sub.shape[0])):\n",
    "    if disp_count >= 10:\n",
    "        break\n",
    "    fn = jp('data', 'test', 'audio', sub.loc[i, 'fname'])\n",
    "    label = sub.loc[i, 'label']\n",
    "    if label == 'go' and np.random.rand() > 0.8:\n",
    "        print(fn, label)\n",
    "        display(Audio(fn, autoplay=True))\n",
    "        sleep(1)\n",
    "        disp_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(5)\n",
    "sub = pd.read_csv('submission_034_all_labels.csv')\n",
    "label2int = get_label2int(wanted_only=True)\n",
    "disp_count = 0\n",
    "for i in reversed(range(sub.shape[0])):\n",
    "    if disp_count >= 2:\n",
    "        break\n",
    "    label = sub.loc[i, 'label']\n",
    "    if label == 'silence' and np.random.rand() > 0.999:\n",
    "        fn = jp('data', 'test', 'audio', sub.loc[i, 'fname'])\n",
    "        rate, data = wf.read(fn)\n",
    "        data = np.float32(data) / 32767\n",
    "        # data = np.sqrt(data) + 0.5\n",
    "        data = 10 ** (data) - 1.0\n",
    "        plot_audio(data, normed=True)\n",
    "        print(fn, label)\n",
    "        float_audio(data, autoplay=True)\n",
    "        sleep(1)\n",
    "        disp_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare two submissions\n",
    "# sub1 = pd.read_csv('submission_091_all_labels.csv')\n",
    "# sub2 = pd.read_csv('submission_091_4x_tta_all_labels.csv')\n",
    "\n",
    "sub1 = pd.read_csv('submission_091_all_labels.csv')\n",
    "sub2 = pd.read_csv('submission_091_leftloud_tta_all_labels.csv')\n",
    "num_different = 0\n",
    "\n",
    "for i in tqdm(reversed(range(sub1.shape[0]))):\n",
    "    fn = sub1.loc[i, 'fname']\n",
    "    assert fn == sub2.loc[i, 'fname']\n",
    "    label1 = sub1.loc[i, 'label']\n",
    "    label2 = sub2.loc[i, 'label']\n",
    "    if label1 != label2:\n",
    "        num_different += 1\n",
    "        print(\"%s vs. %s\" % (label1, label2))\n",
    "        in_fn = jp('data/test/audio', fn)\n",
    "        display(Audio(in_fn, autoplay=True))\n",
    "        sleep(1)\n",
    "print(\"%d of %d are different\" % (num_different, sub1.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listen to submission with probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Wanted: \", get_classes(wanted_only=True))\n",
    "print(\"All: \", get_classes(wanted_only=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('submission_100_leftloud_tta_all_labels_probs.csv')\n",
    "label2int = get_label2int(wanted_only=False)\n",
    "int2label = get_int2label(wanted_only=False)\n",
    "disp_count = 0\n",
    "for i in reversed(range(sub.shape[0])):\n",
    "    if disp_count >= 5:\n",
    "        break\n",
    "    fn = jp('data', 'test', 'audio', sub.loc[i, 'fname'])\n",
    "    label = sub.loc[i, 'label']\n",
    "    if label == 'no' and np.random.rand() > 0.99:\n",
    "        probs = sub.loc[i, label2int.keys()]\n",
    "        max_prob = probs.max()\n",
    "        if max_prob < 0.5:\n",
    "            plt.figure()\n",
    "            plt.title(str(disp_count))\n",
    "            plt.bar(range(len(probs)), probs)\n",
    "            plt.axis([0, len(probs), 0, 1])\n",
    "            plt.xticks(range(len(probs)), label2int.keys(), rotation='vertical')\n",
    "            display(Audio(fn, autoplay=True))\n",
    "            sleep(1)\n",
    "            disp_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct broken submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_broken = pd.read_csv('submission_012.csv')\n",
    "sub_all = pd.read_csv('submission_012_all_labels.csv')\n",
    "sub_broken.loc[(sub_all.label == 'unknown').values, 'label'] = 'silence'\n",
    "sub_broken.to_csv('submission_012_corrected.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('submission_012_corrected.csv')\n",
    "disp_count = 0\n",
    "for i in range(sub.shape[0]):\n",
    "    if disp_count >= 10:\n",
    "        break\n",
    "    fn = jp('data', 'test', 'audio', sub.loc[i, 'fname'])\n",
    "    label = sub.loc[i, 'label']\n",
    "    if label != 'unknown' and np.random.rand() > 0.9:\n",
    "        print(label)\n",
    "        display(Audio(fn, autoplay=True))\n",
    "        sleep(1)\n",
    "        disp_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('submission_012_all_labels.csv')\n",
    "counts = sub.label.value_counts()\n",
    "percent_counts = counts.apply(lambda x: np.round(100.0 * (x / sub.shape[0])))\n",
    "# print(counts)\n",
    "print(percent_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check what the generators are producing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.callbacks import TensorBoard\n",
    "from callbacks import ConfusionMatrixCallback\n",
    "from model import speech_model, prepare_model_settings\n",
    "from input_data import AudioProcessor, prepare_words_list\n",
    "from classes import get_classes\n",
    "from IPython import embed  # noqa\n",
    "\n",
    "\n",
    "def data_gen(audio_processor, sess,\n",
    "             batch_size=128,\n",
    "             background_frequency=0.5, background_volume_range=0.2,\n",
    "             foreground_frequency=0.5, foreground_volume_range=0.2,\n",
    "             time_shift_frequency=1.0, time_shift_range=[-2000, 0],\n",
    "             mode='validation', pseudo_frequency=0.4):\n",
    "  offset = 0\n",
    "  if mode != 'training':\n",
    "    background_frequency = 0.0\n",
    "    background_volume_range = 0.0\n",
    "    foreground_frequency = 0.0\n",
    "    foreground_volume_range = 0.0\n",
    "    pseudo_frequency = 0.0\n",
    "    time_shift_frequency = 0.0\n",
    "    time_shift_range = [0, 0]\n",
    "  while True:\n",
    "    X, y = audio_processor.get_data(\n",
    "        how_many=batch_size, offset=0 if mode == 'training' else offset,\n",
    "        background_frequency=background_frequency,\n",
    "        background_volume_range=background_volume_range,\n",
    "        foreground_frequency=foreground_frequency,\n",
    "        foreground_volume_range=foreground_volume_range,\n",
    "        time_shift_frequency=time_shift_frequency,\n",
    "        time_shift_range=time_shift_range,\n",
    "        mode=mode, sess=sess,\n",
    "        pseudo_frequency=pseudo_frequency)\n",
    "    offset += batch_size\n",
    "    if offset > ap.set_size(mode) - batch_size:\n",
    "      offset = 0\n",
    "    yield X, y\n",
    "\n",
    "\n",
    "# running_mean: -0.8 | running_std: 7.0\n",
    "# mfcc running_mean: -0.67 | running_std: 7.45\n",
    "# background_clamp running_mean: -0.00064 | running_std: 0.0774, p5: -0.074, p95: 0.0697  # noqa\n",
    "# 10 ** raw - 1.0 running_mean: 0.017 | 10 ** raw - 1.0 running_std: 0.28\n",
    "# np.log(11) ~ 2.4\n",
    "# np.log(12) ~ 2.5\n",
    "# np.log(32) ~ 3.5\n",
    "# np.log(48) ~ 3.9\n",
    "# 64727 training files\n",
    "if __name__ == '__main__':\n",
    "  # restrict gpu usage: https://stackoverflow.com/questions/34199233/how-to-prevent-tensorflow-from-allocating-the-totality-of-a-gpu-memory  # noqa\n",
    "  gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.90)\n",
    "  sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "  K.set_session(sess)\n",
    "  data_dirs = ['data/train/audio']\n",
    "  add_pseudo = True\n",
    "  if add_pseudo:\n",
    "    data_dirs.append('data/pseudo/audio')\n",
    "  output_representation = 'raw'\n",
    "  sample_rate = 16000\n",
    "  batch_size = 384\n",
    "  classes = get_classes(wanted_only=False, extend_reversed=False)\n",
    "  model_settings = prepare_model_settings(\n",
    "      label_count=len(prepare_words_list(classes)), sample_rate=sample_rate,\n",
    "      clip_duration_ms=1000, window_size_ms=30.0, window_stride_ms=10.0,\n",
    "      dct_coefficient_count=40)\n",
    "  ap = AudioProcessor(\n",
    "      data_dirs=data_dirs, wanted_words=classes,\n",
    "      silence_percentage=15.0, unknown_percentage=5.0,\n",
    "      validation_percentage=10.0, testing_percentage=0.0,\n",
    "      model_settings=model_settings,\n",
    "      output_representation=output_representation)\n",
    "  train_gen = data_gen(ap, sess, batch_size=batch_size, mode='training')\n",
    "  val_gen = data_gen(ap, sess, batch_size=batch_size, mode='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(int2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2label = get_int2label(wanted_only=False)\n",
    "X, y = next(train_gen)\n",
    "for j in range(X.shape[0]):\n",
    "    label = int2label[y[j].argmax()]\n",
    "    if label == 'sheila':\n",
    "        data = X[j, :].squeeze()\n",
    "        float_audio(data, autoplay=True)\n",
    "        sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ap.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted_words = get_classes(wanted_only=True)\n",
    "print(wanted_words)\n",
    "labels2int = {v: k for k, v in ap.word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf data/train/audio/_silence_\n",
    "!mkdir data/train/audio/_silence_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save silence samples to '_silence_'\n",
    "disp_count = 0\n",
    "for i in range(100):\n",
    "    print(disp_count)\n",
    "    if disp_count > 100:\n",
    "        break\n",
    "    X, y = next(train_gen)\n",
    "    y = y.argmax(axis=-1)\n",
    "    for j in range(len(y)):\n",
    "        if y[j] == 0:\n",
    "            print(labels2int[y[j]])\n",
    "            out_fn = jp('data/train/audio/_silence_/%05d.wav' % disp_count)\n",
    "            data = np.int16(X[j, :] * 32768)\n",
    "            wf.write(out_fn, 16000, data)\n",
    "            # float_audio(X[j, :], autoplay=True)\n",
    "            # sleep(1)\n",
    "            disp_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and check where we go wrong in the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = speech_model(\n",
    "  'conv_1d_time',\n",
    "  model_settings['fingerprint_size'] if compute_mfcc else sample_rate,\n",
    "  num_classes=model_settings['label_count'])\n",
    "model.load_weights('checkpoints_014/ep-039-loss-0.173.hdf5')\n",
    "disp_count = 0\n",
    "for i in range(ap.set_size('validation') // batch_size):\n",
    "    if disp_count >= 10:\n",
    "        break\n",
    "    X, y_true = next(val_gen)\n",
    "    y_true = y_true.argmax(axis=-1)\n",
    "    y_pred = model.predict(X).argmax(axis=-1)\n",
    "    for j in range(len(y_true)):\n",
    "        if y_true[j] != y_pred[j] and np.random.rand() > 0.5:\n",
    "            l_true = labels2int[y_true[j]]\n",
    "            l_pred = labels2int[y_pred[j]]\n",
    "            print(\"Pred: %s, Actual: %s\" % (l_pred, l_true))\n",
    "            float_audio(X[j, :], autoplay=True)\n",
    "            sleep(1)\n",
    "            disp_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create \"unknown\" words\n",
    "### Just reverse some of the unwanted words. Reversing the wanted words might actually cause some problems when using global pooling in the end?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exclude_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted_words = get_classes(wanted_only=True)\n",
    "# wow reversed is wow! one reversed sounds like no!\n",
    "# dog vs go :P\n",
    "exclude_words = wanted_words + ['_background_noise_', 'wow', 'one', 'dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = sorted(glob(jp('data', 'train', 'audio', '*', '*.wav')))\n",
    "print(len(fns))\n",
    "fns = [fn for fn in fns if fn.split('/')[-2] not in exclude_words]\n",
    "print(len(fns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_classes = list(set([fn.split('/')[-2] for fn in fns]))\n",
    "# new_classes.remove('_silence_')\n",
    "new_classes = ['new_' + new_class[::-1] for new_class in new_classes]\n",
    "print(new_classes)\n",
    "for new_class in new_classes:\n",
    "    new_dir = jp('data/train/audio', new_class)\n",
    "    if os.path.exists(new_dir):\n",
    "        rmtree(new_dir)\n",
    "    os.mkdir(new_dir)\n",
    "    print(\"created %s\" % new_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(fns)\n",
    "# fn_selection = np.random.choice(fns, size=5000, replace=False)\n",
    "fn_selection = fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there (often) 5 times the same speaker said the same word\n",
    "# \n",
    "# ./eight/5fadb538_nohash_4.wav\n",
    "# ./eight/5fadb538_nohash_3.wav\n",
    "# ./eight/5fadb538_nohash_2.wav\n",
    "# ./eight/5fadb538_nohash_1.wav\n",
    "# ./eight/5fadb538_nohash_0.wav\n",
    "\n",
    "counter = {cn: 0 for cn in new_classes}\n",
    "for fn in tqdm(fn_selection):\n",
    "    cn = 'new_' + fn.split('/')[-2][::-1]\n",
    "    sample_rate, data = wf.read(fn)\n",
    "    bn = os.path.basename(fn)\n",
    "    dst = jp('data', 'train', 'audio', cn,\n",
    "             \"%06d.wav\" % counter[cn])\n",
    "    counter[cn] += 1\n",
    "    data = data[::-1]\n",
    "    wf.write(dst, sample_rate, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take a look at the noise files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_files = sorted(glob(jp('data', 'train', 'audio', '_background_noise_', '*.wav')))\n",
    "background_volumne = 0.8\n",
    "for fn in background_files[5:6]:\n",
    "    print(fn)\n",
    "    rate, data = wf.read(fn)\n",
    "    if len(data) > 16000:\n",
    "        data = data[:16000]\n",
    "    data = np.float32(data) / 32768\n",
    "    data *= background_volumne\n",
    "    print(data.max())\n",
    "    wf.write('tmp.wav', 16000, np.int16(data * 32767))\n",
    "    plot_audio(data, normed=True)\n",
    "    display(Audio('tmp.wav', autoplay=True))\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?wf.write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take a look at \"happy\" files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_files = sorted(glob(jp('data', 'train', 'audio', 'happy', '*.wav')))\n",
    "volumne = 10**1\n",
    "for fn in background_files[5:6]:\n",
    "    print(fn)\n",
    "    rate, data = wf.read(fn)\n",
    "    if len(data) > 16000:\n",
    "        data = data[:16000]\n",
    "    data = np.float32(data) / 32768\n",
    "    data *= volumne\n",
    "    data = np.clip(data, -1, 1)\n",
    "    print(data.max())\n",
    "    wf.write('tmp.wav', 16000, np.int16(data * 32767))\n",
    "    plot_audio(data, normed=True)\n",
    "    display(Audio('tmp.wav', autoplay=True))\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Majority vote submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import join as jp\n",
    "from shutil import copy\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "sub_fns = ['submission_011.csv', 'submission_017.csv',\n",
    "           'submission_018.csv', 'submission_014.csv',\n",
    "           'submission_020.csv']\n",
    "subs = [pd.read_csv(sub_fn) for sub_fn in sub_fns]\n",
    "\n",
    "fname, label = [], []\n",
    "clear_majority = 0\n",
    "for i in tqdm(range(subs[0].shape[0])):\n",
    "    fname.append(subs[0].loc[i, 'fname'])\n",
    "    label_counts = {}\n",
    "    for sub in subs:\n",
    "        ll = sub.loc[i, 'label']\n",
    "    if ll in label_counts:\n",
    "        label_counts[ll] += 1\n",
    "    else:\n",
    "        label_counts[ll] = 1\n",
    "\n",
    "    maj_label = max(label_counts, key=label_counts.get)\n",
    "    if label_counts[maj_label] > 2:\n",
    "        clear_majority += 1\n",
    "    else:\n",
    "        # in trouble save the wav files!\n",
    "        src = jp('data', 'test', 'audio', fname[-1])\n",
    "        dst = jp('split_decision', str(label_counts) + fname[-1])\n",
    "        copy(src, dst)\n",
    "    # resolve tie by chosing 'unknown' or 'silence' if available\n",
    "    if 'unknown' in label_counts and 'silence' in label_counts:\n",
    "        maj_label = 'silence'\n",
    "    elif 'unknown' in label_counts:\n",
    "        maj_label = 'unknown'\n",
    "    elif 'silence' in label_counts:\n",
    "        maj_label = 'silence'\n",
    "    label.append(maj_label)\n",
    "\n",
    "pd.DataFrame({'fname': fname, 'label': label}).to_csv(\n",
    "    'majority_sub_011.csv', index=False)\n",
    "print(\"Done! Got a clear majority for %d of %d samples.\"\n",
    "      % (clear_majority, subs[0].shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate more background noise\n",
    "## The idea is to take the reversed words and average some of them up to generate ~30s tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unwanted words reversed\n",
    "fns = sorted(glob(jp('data', 'train', 'audio', 'unwrev', '*.wav')))\n",
    "print(len(fns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "louder = 16.0  # make it louder!\n",
    "sample_secs = 30\n",
    "total_new = 0\n",
    "num_noise_tracks = 400\n",
    "noise_track = []\n",
    "noise_track_counter = 0\n",
    "sample_track = []\n",
    "sample_counter = 0\n",
    "for fn in tqdm(fns):\n",
    "    sample_rate, data = wf.read(fn)\n",
    "    data = np.float32(data) / 32768\n",
    "    assert sample_rate == 16000\n",
    "    data = center_pad(data)\n",
    "    shift = np.random.randint(16000)\n",
    "    data = np.roll(data, shift)\n",
    "    sample_track.append(data)\n",
    "    sample_counter += 1\n",
    "    if sample_counter == sample_secs:\n",
    "        noise_track.append(np.concatenate(sample_track))\n",
    "        sample_track = []\n",
    "        sample_counter = 0\n",
    "        noise_track_counter += 1\n",
    "        if noise_track_counter == num_noise_tracks:\n",
    "            noise_track = np.array(noise_track)\n",
    "            noise_track = np.mean(noise_track, axis=0) * louder\n",
    "            noise_track = np.int16(noise_track * 32768)\n",
    "            out_fn = jp('data', 'train', 'audio', '_background_noise_', 'silence_please_%04d.wav' % total_new)\n",
    "            wf.write(out_fn, 16000, noise_track)\n",
    "            print(out_fn)\n",
    "            display(Audio(out_fn))\n",
    "            noise_track = []\n",
    "            noise_track_counter = 0\n",
    "            total_new += 1\n",
    "            if total_new == 2:\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does foreground with mixed background sound?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "background_noise_fns = sorted(glob('data/train/audio/_background_noise_/*.wav'))\n",
    "idx = -3\n",
    "print(background_noise_fns[idx])\n",
    "display(Audio(background_noise_fns[idx], autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foreground_fns = sorted(glob('data/train/audio/go/*.wav'))\n",
    "for i in range(3):\n",
    "    foreground_fn = np.random.choice(foreground_fns)\n",
    "    foreground = normalized_read(foreground_fn)\n",
    "    background_fn = np.random.choice(background_noise_fns)\n",
    "    # background_fn = background_noise_fns[-3]\n",
    "    print(background_fn)\n",
    "    background = normalized_read(background_fn)\n",
    "    mixed = np.random.uniform(0.8, 1.2) * foreground + 0.3 * background  # np.random.uniform(0, 2)\n",
    "    mixed = np.clip(mixed, -1, 1)\n",
    "    float_audio(mixed, autoplay=True)\n",
    "    plot_audio(mixed, normed=True)\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How do the models perform on the validation set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import TensorBoard\n",
    "from model import speech_model, prepare_model_settings\n",
    "from input_data import AudioProcessor, prepare_words_list\n",
    "from keras.models import load_model\n",
    "from classes import get_classes\n",
    "\n",
    "\n",
    "def data_gen(audio_processor, sess,\n",
    "             batch_size=128,\n",
    "             background_frequency=0.5, background_volume_range=0.2,\n",
    "             foreground_frequency=1.0, foreground_volume_range=3.0,\n",
    "             time_shift=(100.0 * 16000.0) / 1000,\n",
    "             mode='validation'):\n",
    "    offset = 0\n",
    "    if mode != 'training':\n",
    "        background_frequency = 0.0\n",
    "        background_volume_range = 0.0\n",
    "        foreground_frequency = 0.0\n",
    "        foreground_volume_range = 0.0\n",
    "        time_shift = 0\n",
    "\n",
    "    while True:\n",
    "        X, y = audio_processor.get_data(\n",
    "            how_many=batch_size, offset=0 if mode == 'training' else offset,\n",
    "            background_frequency=background_frequency,\n",
    "            background_volume_range=background_volume_range,\n",
    "            foreground_frequency=foreground_frequency,\n",
    "            foreground_volume_range=foreground_volume_range,\n",
    "            time_shift=time_shift, mode=mode, sess=sess)\n",
    "        offset += batch_size\n",
    "        if offset > ap.set_size(mode) - batch_size:\n",
    "            offset = 0\n",
    "        yield X, y\n",
    "\n",
    "\n",
    "sess = K.get_session()\n",
    "data_dirs = ['data/train/audio']\n",
    "add_pseudo = False\n",
    "if add_pseudo:\n",
    "    data_dirs.append('data/pseudo/audio')\n",
    "compute_mfcc = False\n",
    "sample_rate = 16000\n",
    "batch_size = 64\n",
    "classes = get_classes(wanted_only=False)\n",
    "model_settings = prepare_model_settings(\n",
    "  label_count=len(prepare_words_list(classes)), sample_rate=sample_rate,\n",
    "  clip_duration_ms=1000, window_size_ms=30.0, window_stride_ms=10.0,\n",
    "  dct_coefficient_count=40)\n",
    "ap = AudioProcessor(\n",
    "  data_dirs=data_dirs,\n",
    "  silence_percentage=15.0,\n",
    "  unknown_percentage=7.0,\n",
    "  wanted_words=classes,\n",
    "  validation_percentage=10.0,\n",
    "  testing_percentage=0.0,\n",
    "  model_settings=model_settings,\n",
    "  compute_mfcc=compute_mfcc)\n",
    "train_gen = data_gen(ap, sess, batch_size=batch_size, mode='training')\n",
    "val_gen = data_gen(ap, sess, batch_size=batch_size, mode='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fns = [\n",
    "    'checkpoints_019/ep-022-vl-0.2916.hdf5',\n",
    "    'checkpoints_018/ep-049-vl-0.2185.hdf5',\n",
    "    'checkpoints_017/ep-036-vl-0.1969.hdf5'\n",
    "]\n",
    "\n",
    "models = []\n",
    "for model_fn in model_fns:\n",
    "    model = load_model(model_fn)\n",
    "    models.append((model_fn, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate on validation set\n",
    "for model in models:\n",
    "    out = model.evaluate_generator(\n",
    "        val_gen, steps=ap.set_size('validation') // batch_size)\n",
    "    print(model_fn, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict samples with models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ap.words_list), len(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(val_gen)\n",
    "sample_idx = 10\n",
    "float_audio(X[sample_idx, :], autoplay=True)\n",
    "out_probs = []\n",
    "for model_fn, model in models:\n",
    "    y_preds = model.predict(X)\n",
    "    out_probs.append((model_fn, y_preds[sample_idx]))\n",
    "\n",
    "for fn, pred in out_probs:\n",
    "    plt.figure()\n",
    "    plt.title(fn)\n",
    "    plt.bar(range(len(pred)), pred)\n",
    "    plt.xticks(range(len(pred)), ap.words_list, rotation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrong ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_plots = 2\n",
    "plot_c = 0\n",
    "model = models[-1][-1]\n",
    "while plot_c < max_plots:\n",
    "    X, y = next(val_gen)\n",
    "    y_preds = model.predict(X)\n",
    "    for i, y_pred in enumerate(y_preds):\n",
    "        if plot_c >= max_plots:\n",
    "            break\n",
    "        if y_pred.argmax() != y[i].argmax():\n",
    "            float_audio(X[i, :], autoplay=True)\n",
    "            sleep(1)\n",
    "            plt.figure()\n",
    "            plt.title(\"Pred: %s, Actual: %s\"\n",
    "                      % (ap.words_list[y_pred.argmax()], ap.words_list[y[i].argmax()]))\n",
    "            plt.bar(range(len(y_pred)), y_pred)\n",
    "            plt.xticks(range(len(y_pred)), ap.words_list, rotation='vertical')\n",
    "            plot_c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What happens if we just feed plain silence e.g. all 0?\n",
    "### Looks good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((2, 16000), dtype=np.float32)\n",
    "pred = model.predict(X)\n",
    "float_audio(X[0, :], autoplay=True)\n",
    "sleep(1)\n",
    "plt.figure()\n",
    "plt.title(\"Silence pred\")\n",
    "plt.bar(range(len(pred[0])), pred[0])\n",
    "_ = plt.xticks(range(len(pred[0])), ap.words_list, rotation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How about the noise files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_fns[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_fns = glob(jp('data/train/audio/_background_noise_/*.wav'))\n",
    "X = []\n",
    "for noise_fn in noise_fns:\n",
    "    X.append(normalized_read(noise_fn))\n",
    "X = np.float32(X)\n",
    "# change volumne\n",
    "X *= 0.2\n",
    "y_pred = model.predict(X)\n",
    "for i in range(X.shape[0]):\n",
    "    # float_audio(X[0, :], autoplay=True)\n",
    "    # sleep(1)\n",
    "    plt.figure()\n",
    "    plt.title(\"Noise pred: %s\" % noise_fns[i])\n",
    "    plt.bar(range(len(y_pred[i])), y_pred[i])\n",
    "    _ = plt.xticks(range(len(y_pred[i])), ap.words_list, rotation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission with averaged probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.00000001  0.99999999  1.00000002  1.00000001  1.00000001  1.00000001\n",
      "  1.00000003  0.99999999  1.          0.99999997]\n",
      "(158538, 32)\n"
     ]
    }
   ],
   "source": [
    "sub_fns = [\n",
    "    'submission_091_leftloud_tta.csv',\n",
    "    'submission_106_tta_leftloud.csv']\n",
    "sub_fns = [fn.replace('.csv', '_all_labels_probs.csv')\n",
    "           for fn in sub_fns]\n",
    "\n",
    "subs = []\n",
    "for sub_fn in sub_fns:\n",
    "    subs.append(pd.read_csv(sub_fn))\n",
    "\n",
    "wanted_words = prepare_words_list(get_classes(wanted_only=True))\n",
    "int2label = get_int2label(wanted_only=False)\n",
    "label2int = get_label2int(wanted_only=False)\n",
    "\n",
    "avg = 0.0\n",
    "for sub in subs:\n",
    "    avg += sub.loc[:, label2int.keys()].values / len(subs)\n",
    "\n",
    "print(avg.sum(axis=1)[10:20])\n",
    "probabilities = avg\n",
    "print(probabilities.shape)\n",
    "preds = probabilities.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158538/158538 [00:00<00:00, 910315.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "ensemble_label = []\n",
    "ensemble_sub = subs[0].copy()\n",
    "for i in tqdm(range(ensemble_sub.shape[0])):\n",
    "    label = int2label[preds[i]]\n",
    "    # print(\"%s with: %.3f\" % (label, probabilities[i, preds[i]]))\n",
    "    label = label if label != '_silence_' else 'silence'\n",
    "    label = label if label != '_unknown_' else 'unknown'\n",
    "    # label = label if label == 'silence' or label in wanted_words else 'unknown'\n",
    "    ensemble_label.append(label)\n",
    "\n",
    "ensemble_sub['label'] = ensemble_label\n",
    "ensemble_sub[['fname', 'label']].to_csv('prob_ensemble_026_all_labels.csv', index=False)\n",
    "ensemble_sub.loc[:, label2int.keys()] = probabilities\n",
    "ensemble_sub.to_csv('prob_ensemble_026_all_labels_probs.csv', index=False)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158538/158538 [00:00<00:00, 215096.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1054 of 158538 with small prob\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "ensemble_label = []\n",
    "ensemble_sub = subs[0].copy()\n",
    "small_prob_counter = 0\n",
    "prob_thresh = 0.2\n",
    "for i in tqdm(range(ensemble_sub.shape[0])):\n",
    "    label = int2label[preds[i]]\n",
    "    label = label if label != '_silence_' else 'silence'\n",
    "    label = label if label != '_unknown_' else 'unknown'\n",
    "    label = label if label == 'silence' or label in wanted_words else 'unknown'\n",
    "    # handle \"small\" probs\n",
    "    max_prob = probabilities[i, preds[i]]\n",
    "    if max_prob < prob_thresh:\n",
    "        small_prob_counter += 1\n",
    "        src_fn = jp('data/test/audio', ensemble_sub.loc[i, 'fname'])\n",
    "        dst_fn = jp('split_decision', '%s_%.3f.wav'\n",
    "                    % (label, max_prob))\n",
    "        copy(src_fn, dst_fn)\n",
    "        # map small prob words (not silence) to unknown\n",
    "        label = label if label == 'silence' else 'unknown'\n",
    "    ensemble_label.append(label)\n",
    "\n",
    "\n",
    "print(\"%d of %d with small prob\" % (small_prob_counter, ensemble_sub.shape[0]))\n",
    "ensemble_sub['label'] = ensemble_label\n",
    "ensemble_sub[['fname', 'label']].to_csv(\n",
    "    'prob_ensemble_026_thresh_%.2f_map_to_unknown.csv' % prob_thresh, index=False)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find duplicates\n",
    "## https://www.kaggle.com/c/tensorflow-speech-recognition-challenge/discussion/44687"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fns = sorted(glob('data/train/audio/*/*.wav'))\n",
    "test_fns = sorted(glob('data/test/audio/*.wav'))\n",
    "all_fns = train_fns + test_fns\n",
    "print(\"%d train, %d test, %d total\"\n",
    "      % (len(train_fns), len(test_fns), len(all_fns)))\n",
    "all_fns = all_fns[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('md5sums.p'):\n",
    "    md5sums = {}\n",
    "    for fn in tqdm(all_fns):\n",
    "        if fn in md5sums:\n",
    "            print(\"Double fn!\", fn)\n",
    "        checksum = md5(fn)\n",
    "        md5sums[fn] = checksum\n",
    "    # cache\n",
    "    data = {'md5sums': md5sums}\n",
    "    with open('md5sums.p', 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "with open('md5sums.p', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    md5sums = data['md5sums']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {}\n",
    "checksum_fn = {v: k for k, v in md5sums.items()}\n",
    "for fn, checksum in md5sums.items():\n",
    "    if checksum in counts:\n",
    "        counts[checksum] += 1\n",
    "    else:\n",
    "        counts[checksum] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_counts = []\n",
    "check_to_fns = {}\n",
    "for checksum, count in counts.items():\n",
    "    fn = checksum_fn[checksum]\n",
    "    fn_counts.append((fn, count))\n",
    "    if checksum in check_to_fns:\n",
    "        if fn not in check_to_fns[fn]:\n",
    "            check_to_fns[fn].append(fn)\n",
    "        else:\n",
    "            check_to_fns[fn] = [fn]\n",
    "fn_counts = sorted(fn_counts, key=lambda x: x[-1], reverse=True)\n",
    "print(fn_counts[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [(k, v) for k, v in counts.items() if v == 3710][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mist_fns = [fn for fn, s in md5sums.items() if s == a[0]]\n",
    "bns = [os.path.basename(fn) for fn in mist_fns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all silence -.- check that we got it right anyway ...\n",
    "some_sub = pd.read_csv('submission_017.csv')\n",
    "for i in range(some_sub.shape[0]):\n",
    "    fn = some_sub.loc[i, 'fname']\n",
    "    if fn in bns:\n",
    "        label = some_sub.loc[i, 'label']\n",
    "        if label != 'silence':\n",
    "            print(label)\n",
    "# check! That was useless -.-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listen test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fns = sorted(glob('data/test/audio/*.wav'))\n",
    "print(len(test_fns))\n",
    "disp_count = 0\n",
    "for test_fn in test_fns:\n",
    "    if disp_count > 10:\n",
    "        break\n",
    "    if np.random.rand() > 0.7:\n",
    "        print(test_fn)\n",
    "        display(Audio(filename=test_fn,\n",
    "                      rate=16000,\n",
    "                      autoplay=True))\n",
    "        sleep(1)\n",
    "        disp_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore subsampled representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fns = sorted(glob('data/test/audio/*.wav'))\n",
    "some_fn = np.random.choice(test_fns)\n",
    "rate, data = wf.read(some_fn)\n",
    "data = np.float32(data) / 32768\n",
    "assert rate == 16000\n",
    "plt.figure()\n",
    "plt.plot(range(len(data)), data, 'g')\n",
    "display(Audio(some_fn, autoplay=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "step = 10\n",
    "colors = ['r', 'g', 'b', 'y', 'b']\n",
    "for i in range(3):\n",
    "    data_slice = data[0::step]\n",
    "    data_slice = np.roll(data_slice, int(-i * 400))\n",
    "    plt.plot(range(len(data_slice)), data_slice, colors[i])\n",
    "    float_audio(data_slice, sample_rate=int(16000 / step), autoplay=True)\n",
    "    sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(some_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "colors = ['r', 'g', 'b', 'y']\n",
    "step = 3\n",
    "for i in range(step):\n",
    "    sub = data[i::step]\n",
    "    plt.plot(range(len(sub)), sub + 2 * i, colors[i % len(colors)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 20\n",
    "float_audio(data[::step], sample_rate=int(16000 / step), autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same thing in keras/tf\n",
    "def time_slice_stack(x, step):\n",
    "    x_slices = []\n",
    "    for i in range(step):\n",
    "        x_slice = x[:, i::step]\n",
    "        x_slice = K.expand_dims(x_slice, axis=-1)\n",
    "        x_slices.append(x_slice)\n",
    "    x_slices = K.concatenate(x_slices, axis=-1)\n",
    "    print(x_slices.shape)\n",
    "    return x_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Input(shape=[16000])\n",
    "x = input_layer\n",
    "x = Lambda(lambda x: time_slice_stack(x, 2))(x)\n",
    "model = Model(input_layer, x)\n",
    "out = model.predict(data.reshape((1, 16000))).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check input representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_show_samples(label='stop'):\n",
    "    fns = sorted(glob('data/train/audio/%s/*.wav' % label))\n",
    "    disp_count = 0\n",
    "    for fn in fns:\n",
    "        if disp_count > 3:\n",
    "            break\n",
    "        rate, data = wf.read(fn)\n",
    "        data = np.float32(data) / 32768\n",
    "        data = pad_crop(data)\n",
    "        print(fn)\n",
    "        plt.figure()\n",
    "        plt.imshow(data.reshape((400, 40)).T)\n",
    "        plt.show()\n",
    "        display(float_audio(data, autoplay=True))\n",
    "        sleep(1)\n",
    "        disp_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_show_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now check mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_samples = 16000\n",
    "window_size_samples = 480\n",
    "window_stride_samples = 160\n",
    "dct_coefficient_count = 40\n",
    "magnitude_squared = False\n",
    "wav_filename_placeholder = tf.placeholder(tf.string, [])\n",
    "wav_loader = io_ops.read_file(wav_filename_placeholder)\n",
    "wav_decoder = contrib_audio.decode_wav(\n",
    "  wav_loader, desired_channels=1,\n",
    "  desired_samples=desired_samples)\n",
    "clamped = tf.clip_by_value(wav_decoder.audio, -1.0, 1.0)\n",
    "spectrogram = contrib_audio.audio_spectrogram(\n",
    "  clamped,\n",
    "  window_size=window_size_samples,\n",
    "  stride=window_stride_samples,\n",
    "  magnitude_squared=magnitude_squared)\n",
    "mfcc = contrib_audio.mfcc(\n",
    "  spectrogram,\n",
    "  wav_decoder.sample_rate,\n",
    "  dct_coefficient_count=dct_coefficient_count)\n",
    "\n",
    "def load_spectrogram(fn):\n",
    "    with tf.Session() as sess:\n",
    "        spectrogram_val = sess.run(\n",
    "            spectrogram, {wav_filename_placeholder: fn})\n",
    "    return spectrogram_val\n",
    "\n",
    "def load_mfcc(fn):\n",
    "    with tf.Session() as sess:\n",
    "        mfcc_val = sess.run(\n",
    "            mfcc, {wav_filename_placeholder: fn})\n",
    "    return mfcc_val\n",
    "\n",
    "def plot_show(label='stop', output='spec', max_disp=3):\n",
    "    fns = sorted(glob('data/train/audio/%s/*.wav' % label))\n",
    "    disp_count = 0\n",
    "    some_data = None\n",
    "    for fn in fns:\n",
    "        if disp_count >= max_disp:\n",
    "            break\n",
    "        if np.random.rand() > 0.9:\n",
    "            if output == 'spec':\n",
    "                spec = load_spectrogram(fn).squeeze()\n",
    "                some_data = spec\n",
    "            elif output == 'mfcc':\n",
    "                mfcc = load_mfcc(fn).squeeze()\n",
    "                some_data = mfcc\n",
    "            plt.figure()\n",
    "            plt.title(fn)\n",
    "            plt.imshow(some_data.T)\n",
    "            plt.colorbar()\n",
    "            plt.show()\n",
    "            disp_count += 1\n",
    "    return some_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_spec = plot_show('sheila', output='spec')\n",
    "print(some_spec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_mfcc = plot_show('stop', output='mfcc', max_disp=3)\n",
    "print(some_mfcc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Time steps: ', (16000 - 480) / 160 + 1)\n",
    "print('Frequencies: ', 16000 / 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??contrib_audio.audio_spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we create a model that does the same? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filter = 257\n",
    "\n",
    "input_layer = Input(shape=[16000])\n",
    "x = input_layer\n",
    "x = Reshape([16000, 1])(x)\n",
    "x = Conv1D(num_filter, window_size_samples, strides=window_stride_samples)(x)\n",
    "model = Model(input_layer, x)\n",
    "\n",
    "def plot_show(model, label='stop'):\n",
    "    fns = sorted(glob('data/train/audio/%s/*.wav' % label))\n",
    "    disp_count = 0\n",
    "    some_spec = None\n",
    "    for fn in fns:\n",
    "        if disp_count > 2:\n",
    "            break\n",
    "        if np.random.rand() > 0.0:\n",
    "            rate, data = wf.read(fn)\n",
    "            data = np.float32(data) / 32768\n",
    "            data = pad_crop(data)\n",
    "            spec = model.predict(data.reshape((1, -1))).squeeze()\n",
    "            some_spec = spec\n",
    "            print(spec.shape)\n",
    "            plt.figure()\n",
    "            plt.title(fn)\n",
    "            plt.imshow(spec.T)\n",
    "            plt.show()\n",
    "            disp_count += 1\n",
    "    return some_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = plot_show(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How about a real trained network? This one gets 94% train accuracy and 89% mean validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('checkpoints_069/ep-060-vl-0.3702.hdf5',\n",
    "                 custom_objects={'relu6': relu6,\n",
    "                                 'DepthwiseConv2D': DepthwiseConv2D})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Concatenate\n",
    "concat_layers = [l for l in model.layers if l.__class__ == Concatenate]\n",
    "print(concat_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = model.layers[3].output\n",
    "# activation = concat_layers[0].output\n",
    "spec_model = Model(model.input, activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    return (x - x.mean()) / x.std()\n",
    "\n",
    "fns = sorted(glob('data/train/audio/go/*.wav'))\n",
    "np.random.shuffle(fns)\n",
    "disp_count = 0\n",
    "for fn in fns:\n",
    "    if disp_count > 2:\n",
    "        break\n",
    "    rate, data = wf.read(fn)\n",
    "    data = np.float32(data) / 32768\n",
    "    data = pad_crop(data)\n",
    "    representation = spec_model.predict(data.reshape((1, -1))).squeeze()\n",
    "    spec = load_spectrogram(fn).squeeze()\n",
    "    spec, representation = norm(spec), norm(representation)\n",
    "    print(spec.shape)\n",
    "    plt.figure()\n",
    "    plt.title(fn)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(representation.T)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(spec.T)\n",
    "    plt.show()\n",
    "    print(representation.shape)\n",
    "    disp_count += 1\n",
    "print(activation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looks like we succesfully decorrelated the channels. Though, it seems like this is not what we really want? There shoud be some relation between groups at least -> Use group convolutions? (g-Sub-seperable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same thing with g-Sub-seperable\n",
    "model = load_model('checkpoints_071/ep-015-vl-0.4296.hdf5',\n",
    "                 custom_objects={'relu6': relu6,\n",
    "                                 'DepthwiseConv2D': DepthwiseConv2D})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Concatenate\n",
    "concat_layers = [l for l in model.layers if l.__class__ == Concatenate]\n",
    "print(concat_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = model.layers[3].output\n",
    "# activation = concat_layers[0].output\n",
    "spec_model = Model(model.input, activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    return (x - x.mean()) / x.std()\n",
    "\n",
    "fns = sorted(glob('data/train/audio/stop/*.wav'))\n",
    "np.random.shuffle(fns)\n",
    "disp_count = 0\n",
    "for fn in fns:\n",
    "    if disp_count > 2:\n",
    "        break\n",
    "    rate, data = wf.read(fn)\n",
    "    data = np.float32(data) / 32768\n",
    "    data = pad_crop(data)\n",
    "    representation = spec_model.predict(data.reshape((1, -1))).squeeze()\n",
    "    spec = load_spectrogram(fn).squeeze()\n",
    "    spec, representation = norm(spec), norm(representation)\n",
    "    print(spec.shape)\n",
    "    plt.figure()\n",
    "    plt.title(fn)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(np.flipud(representation.T))\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(spec.T)\n",
    "    plt.show()\n",
    "    print(representation.shape)\n",
    "    disp_count += 1\n",
    "# print(activation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What representation is actually learned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'checkpoints_069/ep-073-vl-0.3997.hdf5'\n",
    "model = my_load_model('checkpoints_069/ep-073-vl-0.3997.hdf5')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 3  # 4\n",
    "first_layer_weights = model.layers[layer_idx].get_weights()[0].squeeze()\n",
    "first_layer_biases = model.layers[layer_idx].get_weights()[1]\n",
    "# first_layer_weights = model.layers[layer_idx].get_weights()[0].squeeze()\n",
    "# first_layer_weights = first_layer_weights.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_layer_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in first_layer_weights:\n",
    "    plt.figure()\n",
    "    plt.plot(range(len(w)), w)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(first_layer_weights.T, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = np.dot(first_layer_weights.T, first_layer_weights)\n",
    "plt.imshow(corr, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same for the reshape architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = my_load_model('checkpoints_084/ep-087-vl-0.2358.hdf5')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 4\n",
    "first_layer_weights = model.layers[layer_idx].get_weights()[0].squeeze()\n",
    "print(first_layer_weights.shape)\n",
    "plt.figure()\n",
    "plt.imshow(first_layer_weights.T, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_label = 'right'\n",
    "test_fns = sorted(glob('data/train/audio/%s/*.wav' % example_label))\n",
    "int2label = get_int2label(wanted_only=False)\n",
    "num_correct = 0\n",
    "num_total = len(test_fns)\n",
    "vis = True\n",
    "pbar = tqdm(test_fns) if not vis else test_fns\n",
    "for fn in pbar:\n",
    "    rate, data = wf.read(fn)\n",
    "    data = pad_crop(data)\n",
    "    data = np.float32(data) / 32767\n",
    "    prediction = model.predict(data.reshape(1, -1)).squeeze()\n",
    "    label = int2label[prediction.argmax()]\n",
    "    if label != example_label and vis:\n",
    "        print(\"Pred: \", label)\n",
    "        display(Audio(fn, autoplay=True))\n",
    "        sleep(1)\n",
    "    \n",
    "    if label == example_label:\n",
    "        num_correct += 1\n",
    "print(\"Acc: %.3f\" % (float(num_correct) / num_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_model = Model(model.input, model.layers[40].output)\n",
    "print(activation_model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "test_fns = sorted(glob('data/train/audio/stop/*.wav'))\n",
    "int2label = get_int2label(wanted_only=False)\n",
    "for i in range(2):\n",
    "    for fn in [test_fns[np.random.randint(len(test_fns))]]:\n",
    "        print(fn)\n",
    "        rate, data = wf.read(fn)\n",
    "        data = pad_crop(data)\n",
    "        data = np.float32(data) / 32767\n",
    "        act_val = activation_model.predict(data.reshape(1, -1)).squeeze()\n",
    "        print(act_val.min(), act_val.max())\n",
    "        display(Audio(fn, autoplay=True))\n",
    "        plt.figure()\n",
    "        plt.subplot(4, 1, 1)\n",
    "        plt.imshow(cv2.resize(act_val.T, (16000, act_val.shape[0] * 20), interpolation=cv2.INTER_NEAREST))\n",
    "        plt.subplot(4, 1, 2)\n",
    "        plt.plot(data)\n",
    "        plt.subplot(4, 1, 3)\n",
    "        corr_mat = np.dot(act_val, act_val.T)\n",
    "        print(corr_mat.shape)\n",
    "        plt.imshow(cv2.resize(corr_mat, (16000, corr_mat.shape[0] * 20), interpolation=cv2.INTER_NEAREST))\n",
    "        plt.colorbar()\n",
    "        plt.subplot(4, 1, 4)\n",
    "        plt.plot(data[::40])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(16000)\n",
    "print(a.reshape((400, 40)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There are a few wrong labels in the training data. Can we find them using ML?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best single model\n",
    "model = my_load_model('checkpoints_086/ep-110-vl-0.1935.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fns = sorted(glob('data/train/audio/*/*.wav'))\n",
    "train_fns = [fn for fn in train_fns\n",
    "             if fn.split('/')[-2] != '_background_noise_' and\n",
    "             fn.split('/')[-2] != 'unknown_unknown']\n",
    "print(\"Found: %d fns\" % len(train_fns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int2label = get_int2label(wanted_only=False)\n",
    "fns, preds, gts = [], [], []\n",
    "for fn in tqdm(train_fns[:]):\n",
    "    rate, data = wf.read(fn)\n",
    "    if len(data) != 16000:\n",
    "        data = pad_crop(data)\n",
    "    data = np.float32(data) / 32768\n",
    "    pred = model.predict(data.reshape((1, -1))).squeeze()\n",
    "    gt_label = fn.split('/')[-2]\n",
    "    pred_label = int2label[pred.argmax()]\n",
    "    if pred_label != gt_label:\n",
    "        fns.append(fn)\n",
    "        preds.append(pred_label)\n",
    "        gts.append(gt_label)\n",
    "\n",
    "pd.DataFrame({'filename': fns,\n",
    "              'predicted_label': preds,\n",
    "              'gt_label': gts}).to_csv('wrong_train_labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l wrong_train_labels.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_labels = pd.read_csv('wrong_train_labels.csv')\n",
    "print(wrong_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(wrong_labels.shape[0]):\n",
    "    fn = wrong_labels.loc[i, 'filename']\n",
    "    gt = wrong_labels.loc[i, 'gt_label']\n",
    "    pred = wrong_labels.loc[i, 'predicted_label']\n",
    "    if gt == 'stop':\n",
    "        print(\"%s: GT: %s, PRED: %s\" % (fn, gt, pred))\n",
    "        display(Audio(fn, autoplay=True))\n",
    "        sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we speed down the command? This is how I'd repeat something if a person doesn't unterstand me :P (probably louder as well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fns = sorted(glob('data/train/audio/*/*.wav'))\n",
    "print(len(train_fns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(13)\n",
    "fn = np.random.choice(train_fns)\n",
    "print(fn)\n",
    "rate, data = wf.read(fn)\n",
    "if len(data) != 16000:\n",
    "    data = pad_crop(data)\n",
    "data = np.float32(data) / 32767\n",
    "float_audio(data, autoplay=True)\n",
    "print(data.shape)\n",
    "plt.figure()\n",
    "plt.plot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2? lol: https://www.kaggle.com/haqishen/augmentation-methods-for-audio\n",
    "# The pitch chanes (sounds bad!)\n",
    "speed_rate = 0.8\n",
    "w = int(len(data) / speed_rate)\n",
    "print(w)\n",
    "data_fast = data.reshape((1, -1))\n",
    "data_fast = cv2.resize(\n",
    "    data_fast, (w, 1)).squeeze()\n",
    "data_fast = data_fast[4000: 20000]\n",
    "float_audio(data_fast, autoplay=True)\n",
    "plt.figure()\n",
    "plt.plot(data_fast)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the same with librosa\n",
    "### That sounds good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_crop(data, desired_size=16000):\n",
    "    left = (len(data) - desired_size) // 2\n",
    "    return data[left: left + desired_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "speed = 1.3  # float: < 1.0: slow down, > 1.0: speed up\n",
    "data_fast = lr.effects.time_stretch(data, speed)\n",
    "print(data_fast.shape)\n",
    "# data_fast = data_fast[4000: 20000]\n",
    "float_audio(data_fast, autoplay=True)\n",
    "plt.figure()\n",
    "plt.plot(data_fast)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the attention model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16000)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 16000)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 800, 40)      0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 399, 64)      7680        lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 399, 64)      256         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 399, 64)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1, 399, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_1 (DepthwiseCo (None, 1, 399, 64)   192         lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 399, 64)      0           depthwise_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 399, 128)     8192        lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 399, 128)     512         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 399, 128)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1, 399, 128)  0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_2 (DepthwiseCo (None, 1, 399, 128)  384         lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 399, 128)     0           depthwise_conv2d_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 399, 128)     16384       lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 399, 128)     512         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 399, 128)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 200, 128)     8192        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 200, 128)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 200, 128)     512         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 200, 128)     0           max_pooling1d_1[0][0]            \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1, 200, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_3 (DepthwiseCo (None, 1, 200, 128)  384         lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 200, 128)     0           depthwise_conv2d_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 200, 256)     32768       lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 200, 256)     1024        conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 200, 256)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1, 200, 256)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_4 (DepthwiseCo (None, 1, 200, 256)  768         lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 200, 256)     0           depthwise_conv2d_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 200, 256)     65536       lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 200, 256)     1024        conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 200, 256)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 100, 256)     32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 100, 256)     0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 100, 256)     1024        conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 100, 256)     0           max_pooling1d_2[0][0]            \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1, 100, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_5 (DepthwiseCo (None, 1, 100, 256)  768         lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 100, 256)     65536       lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 100, 256)     1024        conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 100, 256)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1, 100, 256)  0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_6 (DepthwiseCo (None, 1, 100, 256)  768         lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 100, 256)     65536       lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 100, 256)     1024        conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 100, 256)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 100, 256)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 100, 256)     0           max_pooling1d_3[0][0]            \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 1, 100, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_7 (DepthwiseCo (None, 1, 100, 256)  768         lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 100, 256)     65536       lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 100, 256)     1024        conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 100, 256)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 1, 100, 256)  0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_8 (DepthwiseCo (None, 1, 100, 256)  768         lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 100, 256)     65536       lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 100, 256)     1024        conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 100, 256)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 100, 256)     0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 100, 256)     0           max_pooling1d_4[0][0]            \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 1, 100, 256)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_9 (DepthwiseCo (None, 1, 100, 256)  768         lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 100, 256)     65536       lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 100, 256)     1024        conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 100, 256)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 1, 100, 256)  0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_10 (DepthwiseC (None, 1, 100, 256)  768         lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 100, 256)     65536       lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 100, 256)     1024        conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 100, 256)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 100, 256)     0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 100, 256)     0           max_pooling1d_5[0][0]            \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 1, 100, 256)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_11 (DepthwiseC (None, 1, 100, 256)  768         lambda_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 100, 256)     65536       lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 100, 256)     1024        conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 100, 256)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 1, 100, 256)  0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_12 (DepthwiseC (None, 1, 100, 256)  768         lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 100, 256)     65536       lambda_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 100, 256)     1024        conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 100, 256)     0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 100, 256)     0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 100, 256)     0           max_pooling1d_6[0][0]            \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 1, 100, 256)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_13 (DepthwiseC (None, 1, 100, 256)  768         lambda_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 100, 256)     65536       lambda_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 100, 256)     1024        conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 100, 256)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 1, 100, 256)  0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_14 (DepthwiseC (None, 1, 100, 256)  768         lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 100, 256)     65536       lambda_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 100, 256)     1024        conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 100, 256)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 100, 256)     0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 100, 256)     0           max_pooling1d_7[0][0]            \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 1, 100, 256)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_15 (DepthwiseC (None, 1, 100, 256)  768         lambda_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 100, 256)     65536       lambda_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 100, 256)     1024        conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 100, 256)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 1, 100, 256)  0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_16 (DepthwiseC (None, 1, 100, 256)  768         lambda_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 100, 256)     65536       lambda_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 100, 256)     1024        conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 100, 256)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 100, 256)     0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 100, 256)     0           max_pooling1d_8[0][0]            \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 1, 100, 256)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_17 (DepthwiseC (None, 1, 100, 256)  768         lambda_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 100, 256)     65536       lambda_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 100, 256)     1024        conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 100, 256)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)              (None, 1, 100, 256)  0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_18 (DepthwiseC (None, 1, 100, 256)  768         lambda_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 100, 256)     65536       lambda_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 100, 256)     1024        conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 100, 256)     0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 100, 256)     0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 100, 256)     0           max_pooling1d_9[0][0]            \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 1, 100, 256)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_19 (DepthwiseC (None, 1, 100, 256)  768         lambda_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 100, 256)     65536       lambda_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 100, 256)     1024        conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 100, 256)     0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 1, 100, 256)  0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_20 (DepthwiseC (None, 1, 100, 256)  768         lambda_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 100, 256)     65536       lambda_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 100, 256)     1024        conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 100, 256)     0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 100, 256)     0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 100, 256)     0           max_pooling1d_10[0][0]           \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 1, 100, 256)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_21 (DepthwiseC (None, 1, 100, 256)  768         lambda_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 100, 256)     0           depthwise_conv2d_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 100, 384)     98304       lambda_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 100, 384)     1536        conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 100, 384)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 1, 100, 384)  0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_22 (DepthwiseC (None, 1, 100, 384)  1152        lambda_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)              (None, 100, 384)     0           depthwise_conv2d_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 100, 384)     147456      lambda_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 100, 384)     1536        conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 100, 384)     0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 50, 384)      98304       add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 50, 384)      0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 50, 384)      1536        conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 50, 384)      0           max_pooling1d_11[0][0]           \n",
      "                                                                 batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 1, 50, 384)   0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_23 (DepthwiseC (None, 1, 50, 384)   1152        lambda_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None, 50, 384)      0           depthwise_conv2d_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 50, 512)      196608      lambda_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 50, 512)      2048        conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 50, 512)      0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 1, 50, 512)   0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_24 (DepthwiseC (None, 1, 50, 512)   1536        lambda_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)              (None, 50, 512)      0           depthwise_conv2d_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 50, 512)      262144      lambda_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 50, 512)      2048        conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 50, 512)      0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 25, 512)      196608      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 25, 512)      0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 25, 512)      2048        conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 25, 512)      0           max_pooling1d_12[0][0]           \n",
      "                                                                 batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)              (None, 1, 25, 512)   0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_25 (DepthwiseC (None, 1, 25, 512)   1536        lambda_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)              (None, 25, 512)      0           depthwise_conv2d_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 25, 728)      372736      lambda_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 25, 728)      2912        conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 25, 728)      0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)              (None, 1, 25, 728)   0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_26 (DepthwiseC (None, 1, 25, 728)   2184        lambda_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)              (None, 25, 728)      0           depthwise_conv2d_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 25, 728)      529984      lambda_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 25, 728)      2912        conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 25, 728)      0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 13, 728)      372736      add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 13, 728)      0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 13, 728)      2912        conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 13, 728)      0           max_pooling1d_13[0][0]           \n",
      "                                                                 batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 9464)         0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 13)           123032      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)              (None, 13, 1)        0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 13, 728)      0           add_13[0][0]                     \n",
      "                                                                 lambda_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 728)          0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 728)          0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           23328       dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,704,416\n",
      "Trainable params: 3,684,048\n",
      "Non-trainable params: 20,368\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = my_load_model('checkpoints_105/ep-012-vl-0.4969.hdf5')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 13, 1)\n"
     ]
    }
   ],
   "source": [
    "attention = Model(model.input, model.layers[-5].output)\n",
    "print(attention.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train/audio/seven/cb164eea_nohash_1.wav\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcFdWZ//HPQzdNQ7M1dMsuDQYlGDVox3WSuKGIDmSW\n3wxmJqNJHCaLyUwyMwn+fMVEs5FtNDFOlJ9DYkyiiUtGFBJFNNHEtVFAFpEWULoBaUCgWXp/fn/c\narjcXrhLdd++t77v1+u+uurUqarnnu5+bt1TVafM3RERkWjpl+0ARESk9yn5i4hEkJK/iEgEKfmL\niESQkr+ISAQp+YuIRFDSyd/MFpnZTjNb08VyM7MfmVm1ma02szPjll1jZhuD1zVhBC4iIulL5cj/\nZ8DMbpZfAUwJXvOAnwCY2Qjgq8A5wNnAV82sNJ1gRUQkHEknf3d/BtjTTZU5wM895gVguJmNAS4H\nlrn7Hnd/F1hG9x8iIiLSwwpD3NY4YGvcfE1Q1lV5B2Y2j9i3BkpKSs6aOnVqiOGJiOS/FStW7HL3\n8uPVCzP5Z8zdFwILASorK72qqirLEYmI5BYzeyuZemFe7VMLTIibHx+UdVUuIiJZEmbyXwz8U3DV\nz7nAPnffDjwOXGZmpcGJ3suCMhERyZKku33M7D7gQqDMzGqIXcHTH8Dd7wSWArOAauAQ8PFg2R4z\n+zrwcrCpW9y9uxPHIiLSw5JO/u5+9XGWO/DZLpYtAhalFpqI9LaK+UtC3+aWBVeGvk3JnO7wFRGJ\nICV/EZEIUvIXEYkgJX8RkQhS8hcRiSAlfxGRCFLyFxGJICV/EZEIUvIXEYkgJX8RkQhS8hcRiSAl\nfxGRCFLyFxGJICV/EZEIUvIXEYkgJX8RkQhKKfmb2Uwz22Bm1WY2v5Plt5rZyuD1hpntjVvWGrds\ncRjBi4hIelJ5jGMBcAcwA6gBXjazxe6+rr2Ou38hrv7ngOlxmzjs7u/PPGQREclUKkf+ZwPV7r7J\n3ZuA+4E53dS/Grgvk+BERKRnpJL8xwFb4+ZrgrIOzGwiMAl4Kq642MyqzOwFM/tIF+vNC+pU1dXV\npRCaiIikoqdO+M4FHnT31riyie5eCXwUuM3MTkpcyd0Xunulu1eWl5f3UGgiIpJK8q8FJsTNjw/K\nOjOXhC4fd68Nfm4C/sCx5wNERKQXpZL8XwammNkkMysiluA7XLVjZlOBUuD5uLJSMxsQTJcBFwDr\nEtcVEZHekfTVPu7eYmbXA48DBcAid19rZrcAVe7e/kEwF7jf3T1u9fcCd5lZG7EPnAXxVwmJiEjv\nSjr5A7j7UmBpQtlNCfNf62S954DT0ohPRER6gO7wFRGJICV/EZEIUvIXEYkgJX8RkQhS8hcRiSAl\nfxGRCFLyFxGJICV/EZEIUvIXEYkgJX8RkQhS8hcRiSAlfxGRCFLyFxGJICV/EZEIUvIXEYkgJX8R\nkQhKKfmb2Uwz22Bm1WY2v5Pl15pZnZmtDF7XxS27xsw2Bq9rwgheRETSk/STvMysALgDmAHUAC+b\n2eJOHsf4a3e/PmHdEcBXgUrAgRXBuu9mFL2IiKQllSP/s4Fqd9/k7k3A/cCcJNe9HFjm7nuChL8M\nmJlaqCIiEpZUkv84YGvcfE1QluhvzGy1mT1oZhNSWdfM5plZlZlV1dXVpRCaiIikIuwTvo8CFe5+\nOrGj+3tSWdndF7p7pbtXlpeXhxyaiIi0SyX51wIT4ubHB2VHuPtud28MZu8Gzkp2XRER6T2pJP+X\ngSlmNsnMioC5wOL4CmY2Jm52NrA+mH4cuMzMSs2sFLgsKBMRkSxI+mofd28xs+uJJe0CYJG7rzWz\nW4Aqd18MfN7MZgMtwB7g2mDdPWb2dWIfIAC3uPueEN+HiIikIOnkD+DuS4GlCWU3xU3fANzQxbqL\ngEVpxCgiIiHTHb4iIhGk5C8iEkFK/iIiEaTkLyISQUr+IiIRpOQvIhJBSv4iIhGk5C8iEkFK/iIi\nEaTkLyISQUr+IiIRpOQvIhJBSv4iIhGk5C8iEkFK/iIiEZRS8jezmWa2wcyqzWx+J8u/aGbrgge4\nLzeziXHLWs1sZfBanLiuiIj0nqQf5mJmBcAdwAygBnjZzBa7+7q4aq8Cle5+yMw+DXwX+Ptg2WF3\nf39IcYuISAZSOfI/G6h2903u3gTcD8yJr+DuT7v7oWD2BWIPahcRkT4mleQ/DtgaN18TlHXlk8Dv\n4uaLzazKzF4ws490toKZzQvqVNXV1aUQmoiIpCKlZ/gmy8z+EagEPhxXPNHda81sMvCUmb3m7m/G\nr+fuC4GFAJWVld4TsYmISGpH/rXAhLj58UHZMczsUuBGYLa7N7aXu3tt8HMT8AdgehrxiohICFJJ\n/i8DU8xskpkVAXOBY67aMbPpwF3EEv/OuPJSMxsQTJcBFwDxJ4pFRKQXJd3t4+4tZnY98DhQACxy\n97VmdgtQ5e6Lge8Bg4EHzAzgbXefDbwXuMvM2oh94CxIuEpIRER6UUp9/u6+FFiaUHZT3PSlXaz3\nHHBaOgGKiEj4dIeviEgEKfmLiESQkr+ISAQp+YuIRJCSv4hIBCn5i4hEkJK/iEgEKfmLiESQkr+I\nSAQp+YuIRJCSv4hIBCn5i4hEkJK/iEgEKfmLiERQjzzGUUTCVTF/Sejb3LLgytC3KblDR/4iIhGU\nUvI3s5lmtsHMqs1sfifLB5jZr4PlL5pZRdyyG4LyDWZ2eeahi4hIupJO/mZWANwBXAFMA642s2kJ\n1T4JvOvu7wFuBb4TrDuN2DN/TwVmAv8dbE9ERLIglSP/s4Fqd9/k7k3A/cCchDpzgHuC6QeBSyz2\nMN85wP3u3ujum4HqYHsiIpIFqZzwHQdsjZuvAc7pqk7wwPd9wMig/IWEdccl7sDM5gHzgtlGM1uT\nQnx9XRmwK9tBhCSf3gvk1/tJ+r3Yd3o4knD2E8nfTYYmJlOpT13t4+4LgYUAZlbl7pVZDik0+fR+\n8um9QH69n3x6L5Bf76evvZdUun1qgQlx8+ODsk7rmFkhMAzYneS6IiLSS1JJ/i8DU8xskpkVETuB\nuzihzmLgmmD6b4Gn3N2D8rnB1UCTgCnAS5mFLiIi6Uq62yfow78eeBwoABa5+1ozuwWocvfFwP8A\n95pZNbCH2AcEQb3fAOuAFuCz7t56nF0uTP3t9Gn59H7y6b1Afr2ffHovkF/vp0+9F4sdmIuISJTo\nDl8RkQhS8hcRiaA+mfyPN4xELjGzCWb2tJmtM7O1Zvav2Y4pU2ZWYGavmtlj2Y4lU2Y23MweNLPX\nzWy9mZ2X7ZjSZWZfCP7G1pjZfWZWnO2YUmFmi8xsZ/z9PWY2wsyWmdnG4GdpNmNMVhfv5XvB39lq\nM/utmQ3PZox9LvknOYxELmkB/t3dpwHnAp/N8fcD8K/A+mwHEZIfAr9396nAGeTo+zKzccDngUp3\nfx+xizLmZjeqlP2M2PAv8eYDy919CrA8mM8FP6Pje1kGvM/dTwfeAG7o7aDi9bnkT3LDSOQMd9/u\n7q8E0/XEkkuHu5tzhZmNB64E7s52LJkys2HAh4hdpYa7N7n73uxGlZFCYGBwj80gYFuW40mJuz9D\n7CrBePFDxtwDfKRXg0pTZ+/F3Z9w95Zg9gVi9ztlTV9M/p0NI5GzyTJeMMrpdODF7EaSkduALwFt\n2Q4kBJOAOuCnQTfW3WZWku2g0uHutcD3gbeB7cA+d38iu1GFYpS7bw+mdwCjshlMiD4B/C6bAfTF\n5J+XzGww8BDwb+6+P9vxpMPMrgJ2uvuKbMcSkkLgTOAn7j4dOEjudCscI+gLn0PsA20sUGJm/5jd\nqMIV3DCa89emm9mNxLqDf5nNOPpi8s+7oSDMrD+xxP9Ld3842/Fk4AJgtpltIdYdd7GZ/SK7IWWk\nBqhx9/ZvYg8S+zDIRZcCm929zt2bgYeB87McUxjeMbMxAMHPnVmOJyNmdi1wFfAPnuWbrPpi8k9m\nGImcEQxp/T/Aenf/r2zHkwl3v8Hdx7t7BbHfy1PunrNHl+6+A9hqZqcERZcQuws9F70NnGtmg4K/\nuUvI0ZPXCeKHjLkGeCSLsWTEzGYS6zKd7e6Hsh1Pn0v+wQmR9mEk1gO/cfe12Y0qIxcAHyN2lLwy\neM3KdlByxOeAX5rZauD9wLeyHE9agm8vDwKvAK8R+9/uU8MJHI+Z3Qc8D5xiZjVm9klgATDDzDYS\n+3azIJsxJquL9/JjYAiwLMgDd2Y1Rg3vICISPX3uyF9ERHqekr+ISASFkvw7u5U5YbmZ2Y+C4RpW\nm1muXlEhIpIXwnqM48+Incz4eRfLryD2AJcpxJ77+xM6Pv/3GGVlZV5RURFSeCIi0bBixYpd7l5+\nvHqhJH93fya4e7Urc4CfB9e1vhAMpjUm7s69DioqKqiqqgojPBGRyDCzt5Kp11t9/kkN2WBm88ys\nysyq6urqeik0EZHo6VMnfN19obtXuntleflxv7WISA+pb2imdu/hbIchPai3kn/eDdkgks9m//jP\nXLDgqWyHIT0orBO+x7MYuN7M7id2ondfd/39IpIddz+7iXXb97N518FshyI9LJTkH9zKfCFQZmY1\nwFeB/gDufiewFJgFVAOHgI+HsV8RCdc3luTDcECSjLCu9rn6OMsd+GwY+xKR8Fx1+7P0M+Pm2ady\nqKm1w/KnN+zk4Vdquf3q6VmITnpSb3X7iEgfcsPDqzlhSDFramOPlvir/36u03of/+nLAEr+eUjJ\nXyRCNr5Tz4iSIu57aevxK0teU/IXiYDLbv0j/3juRG56ZC3DB/XPdjjSB/Sp6/xFJHV7DzVx97Ob\niB+e/bHV2zgc14f/xjsHuOmRtUH95l6PUfoeJX+RHHfjb9fwjSXreXHzHgBWvLWH63/1Krc8lsvP\nQJKepm4fkRx1sLGFzbsOsr8hdiTf2NIGwP6GFgC27W3IWmzS9yn5i+SoT/1iBc9u3MV5k0cC0Nam\np/JJ8tTtI5Kjqra8C0Crkr6kQclfJI+tqd3HoaaWjLfz9Os7Of/by2lo7ngjmOQmdfuI5Kn9Dc1c\ndfufmDFtVMbbuvnRtWzb18D2fQ1MKisJITrJNh35i+Qos+6Xt1/quXLr3tD2GX85qeQ2JX+RHOd0\nnpAt+HQIM18r9ecPJX+RPHX0i0F4KVtXFOUPJX+RHGdBmm//BnCc3qCMzLj1mR7cuvQmJX+RHNWe\n5BO7fXRsLslQ8hcRiSAlf5EcZwkdPYndPrpARzqj5C+S417asqfT8vZLQZX7pTOhJH8zm2lmG8ys\n2szmd7L8WjOrM7OVweu6MPYrEkXuzl/e/icOJjx20R0efqWmR4Z72HtYw0Dnm4zv8DWzAuAOYAZQ\nA7xsZovdfV1C1V+7+/WZ7k8k6l7fUc9rtfs6lP/vym08umobZ1eMCH2fegZA/gnjyP9soNrdN7l7\nE3A/MCeE7YpIJ6744bOdlj+6ahsAuw40Ase/A1iiLYzkPw6IfyBoTVCW6G/MbLWZPWhmEzrbkJnN\nM7MqM6uqq6sLITSR6Ens9NGQDNKZ3jrh+yhQ4e6nA8uAezqr5O4L3b3S3SvLy8t7KTSR/JR4FZBI\nvDCSfy0QfyQ/Pig7wt13u3tjMHs3cFYI+xWRTiTe/NXQ3Ja9YLqxfvt+3tmvp41lSxjJ/2VgiplN\nMrMiYC6wOL6CmY2Jm50NrA9hvyLSjfYj/8N9dAz+K374LOd9e3m2w4isjJO/u7cA1wOPE0vqv3H3\ntWZ2i5nNDqp93szWmtkq4PPAtZnuV0Q6197D3xdP+Lo7j67aduShMG0Ov1+zI8tRRVMoD3Nx96XA\n0oSym+KmbwBuCGNfIpK7nn9zN5+779Vjypa+tp2Z7xudpYiiS3f4iuSZzbsOArC6puO9ANm2v6Hj\nIyXjr0Wq3nmAdw829V5AEabkLyK9prOuqC27DjLv51U0trRy6X/9scv7GCRceoaviPSafp1k/9dq\n9/Fa7T6qtrwLwA5dAdQrdOQvIin59tL1vL5jf1rr9uvmJPSLm3anGZGkQ8lfRFJy1zObmHlbel0z\nnR35t/vRU9XphiRpUPIXkd7TBy8/jSolfxHpNcr9fYeSv4ik5bWafezroXH+N+86yEfu+DP7GzSU\ndE9R8heRtPzlj//Ex/7nxaTqLl//DpXfeJLGluTGGfrBExtYuXUvp3/tiUxClG4o+YtI2pK9keyb\nS9az60Aj/3LviqTqP7Z6eyZhSRJ0nb+I9JhDTS28tfsQm4K7jqXv0JG/iGTk3hfeomL+ElrbnKot\ne2huPdq18y/3rtAdu32Ukr+IZOQr/7sGgJe37OFv73yeBb97nYr5S3hwRQ3Pvakbt/oqJX+RHNKX\nH8n40IoaAF7cHEv43/n967S2ZR5vW5vz4Ioa/ly9K+NtyVFK/iI5ZNINS49fKUseCJJ/Yb9YWml/\nkHymfv78Fv7jgVX8w90v0tDcyi9eeCuU7UadTviKZNGKt/bw7MZdnH9SGWdPGtFt3b581B9v5da9\nAIQV7tceXXdk+vLbnuGt3Yc42NjCv3z4pHB2EFE68hfJgtuXb6Ri/hL+5ifPc9uTG/m7u56nYv4S\nWoKTpW1tzgsJA5311A1VueSt3YcAeHHzHgDOuPkJbl32BgC7DzTyZt2BrMWWa0JJ/mY208w2mFm1\nmc3vZPkAM/t1sPxFM6sIY78ifVFdfSN7DzXxyMpa9h1q5p8WvcTKrXupmL+EnfUNnPut5fwgSFiJ\n3nPj76iYv4R/f2AVcxe+wCd+9jJv7T7IznoNcwwwdfQQAGZMG4W7s+9wMz9cvhGAs77xJJf84I9H\n6u7Y10BTkjeVRZFl+lXSzAqAN4AZQA2xB7pf7e7r4up8Bjjd3T9lZnOBv3L3v+9uu5WVlV5VVZVR\nbCLp2vhOPQcaW5h+YikAL23ewx827GR1zT7+FJx4/PLMqTS3tvFfQSJf9oUPMePWZ3ospl/98zl8\n9P8ld0dtlL104yXcumwj9730NrPPGMu5k0dyyughvPr2u1z3wck0NLdS2M8oLMjs2Lf9A/mEIcVh\nhB0aM1vh7pXHrRdC8j8P+Jq7Xx7M3wDg7t+Oq/N4UOd5MysEdgDl3s3O003+TS1tvPJ27KEQ7Vt3\njkzE/+i0jifUiQ/REyYS1+lufU9YHl+r4zrxNZKIy2NjoWzdc4hzJ49kQP9+PFe9m1mnj2HLroNs\nqjtAcf8CTh03jLXb9jFu+EDKBw9gVXB35knlJRxsbGFnfSOjhhYzbvhAdh9s5EBjK0WF/TjY2MIp\no4dQ39BCQ3MrLa3O+NKBbN51kIqyEhqaW6mrb2RN7T4mjBhE1ZY9nDt5JHsPNzNqyAC2vnuY08YN\nY+ueQ+w60EhxUQGjhxYzpLg/Y4YV8/qOepat28GUE4ZgFjtyHjd8IGOHD2TH/gbGDCumsKAfwwb2\np7Wtjf2HY3FUlJVQ3L+AIcWFbKo7SFNLGwcamzlxRAlNrW3UNzTT5lCz5xBNrW08V72bscOLeXpD\nHQCDigo4a2Ipm+oOUrv3MBItl0w9geWv7zwyP2roAN7Z3/Ek9cSRg3hnfwMNzbFvEQP7F3A4eAB9\nZ8YNH3jM39OVp49h297D7DvUzGWnjua12r1s3XOYD59czoQRA3ly/U4mjSxh5OAiSgYUUt/Qwscv\nqGDU0PQ+VHoz+f8tMNPdrwvmPwac4+7Xx9VZE9SpCebfDOp0ee1Wusl/94FGzvrGkymvJyLSl2z6\n1iz6dff0my4km/z71NU+ZjYPmAdw4oknprWNIcX9+dU/n3N0m8Egsu3PkGhvSot7qETHZUfXPna+\n4/od1+m4z4776WTfCcs632fHuPYfbmbV1r28VrufXQcaqZxYyokjB7F510FOGTWER1ZuY+LIQZQP\nGcC+w80U9DMmlA7iYFMLpYOK2LzrINv3NTB9wnBW1ezlPScMPnJt9sjBRdQ3tLDrQBNTThjMwcYW\n+pmxs76BiSNLWLd9PxNKBzG+dCD7Djfz3Ju7Ke7fjz9uqKOyopRtexv42HkTeXv3IYYOLKR2bwP1\nDc24w6SyEoYP6s8JQ4rZvOsgT2/YSdngIg43tdLmsaP/cyaPoKSoEMd5e88hpo4eysD+BTy/aTdT\nRw+hfMgASooKaWpt4/k3d3PBe8pYVbOXscOKGVxcSENzGzXvHmLDjgMMLS5kZ30jk8pKuDfhUsHC\nfkZLCNejS+644n2j+d2aHQCUDxlAXf3RI/5TRg1hwzv1AMw+YywbdtQfmU/GoKICDjUd/WZw0Snl\n1O49zKGmVs48sZSXNu+hoJ9x5sRSKkYO4sn1OxlZUkRF2SCmjh7KIytr+fLMqWkl/lTkXbePSBi2\n7T3M0IH9GTzg6PFRzbuH+IvvPN2h7pWnj2HJ6u18aeYpfPf3G3osplmnjWbpazt6bPu56EMnl/PM\nG3Udyq8+ewJjhw3kB8ve4OqzT+RTH57M+u31PLOxjq/PeR8F/Yw9B5sYVFRAcf+CtPbd1NLG3sNN\njCwZQEEPJ+pU9Ga3TyGxE76XALXETvh+1N3XxtX5LHBa3Anfv3b3v+tuu0r+0tc1NLfS5s6gomO/\nQLs7rW1+5ITi4lXbuHjqCSxdvZ0vPbSaVV+9jDNu7nyo4n+7dAq3PbmRyWUl3Hjlezl9/HC27zvM\nqWOHUdDPqJi/pMffVy7ZsuBKKuYvYXJ5CQ996nw27z5IUUE/3jduWLZDy5peS/7BzmYBtwEFwCJ3\n/6aZ3QJUuftiMysG7gWmA3uAue6+qbttKvlLPussiU8/cTi//cwF3a5386Nr+emft/RQVH3ftedX\n8JWrplH77mFOHDko2+H0Sb2a/HuCkr/ks8NNrdQ3NHPC0GJ+8MQGbn+qmkXXVnLx1FHdrrezvoGz\nv7m8l6JMzxNf+BA3PbKGRdd+gGk3PR7adrcsuDK0beWznDzhKxIVA4sKGFgU62v+4oyTufCUcs6a\n2P3wDgClg4p6OrSMnTxqCPfPOy/Ubf7xPy8MdXui4R1Ess7Mkkr8AP0zvDGpp102rftvLuk4Y8Jw\nJo4sCX27UacjfxHJ2MxTR3Pnx87qUD6prISJIwfR2NzG85vSG9v/9rnTMw1POqHkLyIZS7ynpd3T\n/3EhEHucY7r9/zqx2zP69ndIEckLiZfDSvYp+YvkmL+rHJ/tEI6Y+4EJFPQzrvvgpFC3e+XpY0Ld\nnnSk5C8iaRs5uIg3vzUrqRPWf/ryRay5+fKktnvHR88E4PTx0b1Zq6fpu5iIpOwTF0xi0Z83c2Yw\n5HUyxpem1nf/py9flBOXtuYqJX8RSdkF7xnJZy46ibLBA3psH6l+WEhq1O0jkmPiR4XNprAS/7Nf\nuoj/uOzkULYlyVPyF5GUlQ9JP/H/ef7Fx8wPLCrg+ounZBqSpEjJX0SS9t4xQ3no0+dx+vjhaW9j\n3PCBVH/zCkoH9QegX8JNAq9/fWZGMUpylPxFctTkst4f8qCwX/JDUXS7nYJ+zDotdjnnwGA8/V/9\n8zk88Knz0h5fX1Kj5C+So0pLOr8S5qFPn9/LkaTn5tmn8spXZhwZ4O78k8r4QEXmHyySHCV/kTyT\nK9fGFxb0Y0QXH2DS85T8RXJUV9f8FHQ10I5IHCV/kRxzvNyezoO/hwcnXyU6lPxFclTih8CQAYUs\n/fwHjynrX2BJPVx8+EAl/6jJKPmb2QgzW2ZmG4Ofnd7rbWatZrYyeC3OZJ8iUff5S6bwwSllXHX6\n2GPKh5f0Z9rYoceUvfa1y1mbxHg6RYWxVDB2WHF4gUqflumR/3xgubtPAZYH85057O7vD16zM9yn\nSKSNHT6Qez95DkOKY6OzvH9C7Jr7xMdxlw7qT3H/gqQunWxf17roUzpl1JD0A5Y+KdOxfeYAFwbT\n9wB/AL6c4TZFJAntebqzXp1XvjLjyNF8Kjz4FBg1dADv7G88Ul4cXI6pc8n5I9Mj/1Huvj2Y3gF0\n9QDPYjOrMrMXzOwjXW3MzOYF9arq6uoyDE0kvyWO8RN/5D+ipIjBA5I/tvv+/zmDD59czqRyPSs3\nKo6b/M3sSTNb08lrTnw9jx0yeBebmejulcBHgdvM7KTOKrn7QnevdPfK8vLyVN+LiCQh/uh9WHCi\n94wJw7nnE2dT0E/XgETFcQ8N3P3SrpaZ2TtmNsbdt5vZGGBnF9uoDX5uMrM/ANOBN9MLWUTgaBLv\n6ogr3k+v/QB19Y1ccdpozIxDTS00tbRRUlRIfUPLkXrFQVdRYfAhMHX0EF7fUc/ooQNYBVz63q6+\n3EuuybTPfzFwDbAg+PlIYoXgCqBD7t5oZmXABcB3M9yvSOSdOjZ2J+/MU0fz6tt7u6170dQTjpmP\n7xKKHybi2399GlNHD2H7vgYeWFFzpHzU0GJe/cqMI98UJPdl+h1vATDDzDYClwbzmFmlmd0d1Hkv\nUGVmq4CngQXuvi7D/YpE3ntOGEz1N684MkBaGEYOHsAXLzvlyLeK+Kt/SkuK0rqBTPqmjI783X03\ncEkn5VXAdcH0c8BpmexHRDoXPz7O339gQujbb7/6Ryk//+gxjiI5rmRAIW9+a1anl3ymq688LUx6\njpK/SB5IZgiHVHhSp5Ell+m6LhHpUld3/EruU/IXkS6df9JIAK4I8aSy9A3q9hGRLp08ajBbFlyZ\n7TCkB+jIX0QkgpT8RaSDvzwjNlx0pZ6pm7fU7SMiHXxwSrm6e/KcjvxFRCJIyV9EJIKU/EVEIsg8\n8dlvfYSZ1QFvZbCJMmBXSOGESXGlRnGlRnGlJh/jmujux30gSp9N/pkys6rgATJ9iuJKjeJKjeJK\nTZTjUrePiEgEKfmLiERQPif/hdkOoAuKKzWKKzWKKzWRjStv+/xFRKRr+XzkLyIiXVDyFxGJoLxL\n/mY208w2mFm1mc3vhf1NMLOnzWydma01s38NykeY2TIz2xj8LA3Kzcx+FMS32szOjNvWNUH9jWZ2\nTUjxFZjZq2b2WDA/ycxeDPb/azMrCsoHBPPVwfKKuG3cEJRvMLPLQ4hpuJk9aGavm9l6MzuvL7SX\nmX0h+B2uMbP7zKw4G+1lZovMbKeZrYkrC619zOwsM3stWOdHluQTW7qI63vB73G1mf3WzIYfrx26\n+h/tqq0+eTNoAAAErElEQVTTiStu2b+bmZtZWV9or6D8c0GbrTWz7/Z2ex3h7nnzAgqAN4HJQBGw\nCpjWw/scA5wZTA8B3gCmAd8F5gfl84HvBNOzgN8Reyb2ucCLQfkIYFPwszSYLg0hvi8CvwIeC+Z/\nA8wNpu8EPh1Mfwa4M5ieC/w6mJ4WtOMAYFLQvgUZxnQPcF0wXQQMz3Z7AeOAzcDAuHa6NhvtBXwI\nOBNYE1cWWvsALwV1LVj3igziugwoDKa/ExdXp+1AN/+jXbV1OnEF5ROAx4ndLFrWR9rrIuBJYEAw\nf0Jvt9eRWDL5J+5rL+A84PG4+RuAG3o5hkeAGcAGYExQNgbYEEzfBVwdV39DsPxq4K648mPqpRnL\neGA5cDHwWPDHuyvun/VIewX/JOcF04VBPUtsw/h6acY0jFiStYTyrLYXseS/NfjnLwza6/JstRdQ\nkZA0QmmfYNnrceXH1Es1roRlfwX8MpjutB3o4n+0u7/NdOMCHgTOALZwNPlntb2IJexLO6nXq+3l\n7nnX7dP+D9yuJijrFcFX/+nAi8Aod98eLNoBjAqmu4qxJ2K/DfgS0BbMjwT2untLJ/s4sv9g+b6g\nfthxTQLqgJ9arDvqbjMrIcvt5e61wPeBt4HtxN7/CrLfXu3Cap9xwXTY8QF8gtiRcTpxdfe3mTIz\nmwPUuvuqhEXZbq+TgQ8G3TV/NLMPpBlXxu2Vb8k/a8xsMPAQ8G/uvj9+mcc+mnv1mlozuwrY6e4r\nenO/SSgk9lX4J+4+HThIrBvjiCy1Vykwh9iH01igBJjZmzEkKxvtczxmdiPQAvyyD8QyCPi/wE3Z\njqUThcS+XZ4L/Cfwm2TPIYQt35J/LbF+vnbjg7IeZWb9iSX+X7r7w0HxO2Y2Jlg+Bth5nBjDjv0C\nYLaZbQHuJ9b180NguJm1P8Qnfh9H9h8sHwbs7oG4aoAad38xmH+Q2IdBttvrUmCzu9e5ezPwMLE2\nzHZ7tQurfWqD6dDiM7NrgauAfwg+mNKJazddt3WqTiL2Ib4q+PsfD7xiZqPTiCvs9qoBHvaYl4h9\nKy9LI67M2yvVvsi+/CL2qbqJ2C++/eTIqT28TwN+DtyWUP49jj1B991g+kqOPeH0UlA+glhfeGnw\n2gyMCCnGCzl6wvcBjj1J9Jlg+rMcewLzN8H0qRx7ImoTmZ/wfRY4JZj+WtBWWW0v4BxgLTAo2Nc9\nwOey1V507CsOrX3oeAJzVgZxzQTWAeUJ9TptB7r5H+2qrdOJK2HZFo72+We7vT4F3BJMn0ysS8d6\nu73c8+yEb9AIs4hdcfMmcGMv7O8viH0FXw2sDF6ziPXJLQc2Eju73/6HZMAdQXyvAZVx2/oEUB28\nPh5ijBdyNPlPDv6Yq4M/nvarDoqD+epg+eS49W8M4t1Aklc6HCee9wNVQZv9b/DPlvX2Am4GXgfW\nAPcG/4i93l7AfcTOOzQTO1L8ZJjtA1QG7/FN4McknHxPMa5qYgms/W//zuO1A138j3bV1unElbB8\nC0eTf7bbqwj4RbC9V4CLe7u92l8a3kFEJILyrc9fRESSoOQvIhJBSv4iIhGk5C8iEkFK/iIiEaTk\nLyISQUr+IiIR9P8BbS0XCYdEgUcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f86dd71be80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train/audio/off/e07dd7d4_nohash_0.wav\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f868e37b358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train/audio/stop/cb8f8307_nohash_5.wav\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f86ddfd6a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train/audio/nine/617de221_nohash_0.wav\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f86dd998208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_fns = sorted(glob('data/train/audio/*/*.wav'))\n",
    "np.random.shuffle(test_fns)\n",
    "disp_count = 0\n",
    "for fn in test_fns:\n",
    "    if disp_count > 3:\n",
    "        break\n",
    "    print(fn)\n",
    "    rate, data = wf.read(fn)\n",
    "    data = np.float32(data) / 32767\n",
    "    data = pad_crop(data)\n",
    "    attention_val = attention.predict(data.reshape((1, -1))).squeeze()\n",
    "    disp_count += 1\n",
    "    # print(attention_val)\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.bar(range(len(attention_val)), attention_val)\n",
    "    plt.axis([0, len(attention_val), 0, 1])\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(range(len(data)), data)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
